{
 "cells": [
  {
   "cell_type": "raw",
   "id": "2919343d",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: langchain_rag.html\n",
    "title: Gradio RAG tutorial with langchain\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68340256",
   "metadata": {},
   "outputs": [],
   "source": "# |default_exp langchain_rag"
  },
  {
   "cell_type": "markdown",
   "id": "15fe30a9-cfeb-4ec0-ae40-334072046464",
   "metadata": {},
   "source": [
    "Please reference [this blog post](https://nbdev.fast.ai/blog/posts/2022-11-07-spaces) on how to use this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf7644f-42b3-4d8d-a1d0-f8c3a2358e27",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca22d1e-1bd0-49c0-9b89-c480ad1a29c4",
   "metadata": {},
   "source": [
    "## Make an app with Gradio"
   ]
  },
  {
   "cell_type": "code",
   "id": "00cf4fad-a920-41dc-be42-3992c7fcefac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T06:07:22.466674Z",
     "start_time": "2025-04-03T06:07:20.719380Z"
    }
   },
   "source": [
    "# |export\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "import getpass\n",
    "\n",
    "from openai import api_key\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "1cc7c77a267305b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T06:07:26.353816Z",
     "start_time": "2025-04-03T06:07:23.214323Z"
    }
   },
   "source": [
    "#| export\n",
    "from llama_index.llms.openrouter import OpenRouter\n",
    "from llama_index.core.llms import ChatMessage\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "9167da2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T06:07:26.365966Z",
     "start_time": "2025-04-03T06:07:26.359386Z"
    }
   },
   "source": [
    "# |export\n",
    "load_dotenv()\n",
    "#os.environ['HTTP_PROXY'] = ''\n",
    "#os.environ['HTTPS_PROXY'] = ''\n",
    "#os.environ['NO_PROXY'] = 'localhost, 127.0.0.1'\n",
    "print(os.environ.get('OPENROUTER_API_KEY'))\n",
    "print(os.environ.get('OPENROUTER_API_URL'))\n",
    "print(os.environ.get('PINECONE_API_KEY'))\n",
    "print(os.environ.get('HTTP_PROXY'))\n",
    "print(os.environ.get('HTTPS_PROXY'))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n",
      "https://openrouter.ai/api/v1\n",
      "pcsk_4JQiw5_Kg3hyxuJet9Dumt7zfnXySGp2xZHoQqLsuvHNiTVD98JysmAEqxRbsJEu41Ko7P\n",
      "http://127.0.0.1:20171\n",
      "http://127.0.0.1:20171\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T07:08:27.158053Z",
     "start_time": "2025-04-03T07:08:27.153485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pinecone import Pinecone, ServerlessSpec, Index\n",
    "import os\n",
    "import pinecone\n",
    "\n",
    "pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))"
   ],
   "id": "47e8825809add8ba",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T07:10:07.195376Z",
     "start_time": "2025-04-03T07:09:59.713983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_name = 'quickstart'\n",
    "if dataset_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        dataset_name,\n",
    "        dimension=1536,\n",
    "        metric=\"euclidean\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\",\n",
    "        )\n",
    "    ),\n",
    "pinecone_index = pc.Index(dataset_name)"
   ],
   "id": "cc5b97fef2bad768",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T07:13:03.989133Z",
     "start_time": "2025-04-03T07:13:03.974583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "vector_store = PineconeVectorStore(pinecone_index=pinecone_index)"
   ],
   "id": "267417287a3eb8c0",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama_index.vector_stores'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[30]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mllama_index\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mvector_stores\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpinecone\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m PineconeVectorStore\n\u001B[32m      2\u001B[39m vector_store = PineconeVectorStore(pinecone_index=pinecone_index)\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'llama_index.vector_stores'"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T07:01:12.665101Z",
     "start_time": "2025-04-03T07:01:10.482312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Embed data\n",
    "data = [\n",
    "    {\"id\": \"vec1\", \"text\": \"Apple is a popular fruit known for its sweetness and crisp texture.\"},\n",
    "    {\"id\": \"vec2\", \"text\": \"The tech company Apple is known for its innovative products like the iPhone.\"},\n",
    "    {\"id\": \"vec3\", \"text\": \"Many people enjoy eating apples as a healthy snack.\"},\n",
    "    {\"id\": \"vec4\", \"text\": \"Apple Inc. has revolutionized the tech industry with its sleek designs and user-friendly interfaces.\"},\n",
    "    {\"id\": \"vec5\", \"text\": \"An apple a day keeps the doctor away, as the saying goes.\"},\n",
    "]\n",
    "\n",
    "embeddings = pc.inference.embed(\n",
    "    model=\"llama-text-embed-v2\",\n",
    "    inputs=[d['text'] for d in data],\n",
    "    parameters={\n",
    "        \"input_type\": \"passage\"\n",
    "    }\n",
    ")\n",
    "\n",
    "vectors = []\n",
    "for d, e in zip(data, embeddings):\n",
    "    vectors.append({\n",
    "        \"id\": d['id'],\n",
    "        \"values\": e['values'],\n",
    "        \"metadata\": {'text': d['text']}\n",
    "    })"
   ],
   "id": "2ef2dd1653a4c24d",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T07:01:17.903444Z",
     "start_time": "2025-04-03T07:01:16.095496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "index.upsert(\n",
    "    vectors=vectors,\n",
    "    namespace=\"ns1\"\n",
    ")"
   ],
   "id": "fbd92364080e7cc7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 5}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T07:04:20.885999Z",
     "start_time": "2025-04-03T07:04:19.914771Z"
    }
   },
   "cell_type": "code",
   "source": "index.describe_index_stats()",
   "id": "726b3dfa59e82b65",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1024,\n",
       " 'index_fullness': 0.0,\n",
       " 'metric': 'euclidean',\n",
       " 'namespaces': {'ns1': {'vector_count': 5}},\n",
       " 'total_vector_count': 5,\n",
       " 'vector_type': 'dense'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "1b77db9df3d720ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T03:40:24.749965Z",
     "start_time": "2025-04-03T03:40:24.746479Z"
    }
   },
   "source": [
    "llm = OpenRouter(\n",
    "    api_key=os.environ.get('OPENROUTER_API_KEY'),\n",
    "    max_tokens=256,\n",
    "    context_window=4096,\n",
    "    model=\"qwen/qwen2.5-vl-32b-instruct:free\"\n",
    "    # model=\"deepseek/deepseek-r1:free\"\n",
    "    # model=\"gryphe/mythomax-l2-13b:free\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T05:37:47.072789Z",
     "start_time": "2025-04-03T05:37:25.931639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "from os import getenv\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=os.environ.get('OPENROUTER_API_URL'),\n",
    "    api_key=os.environ.get('OPENROUTER_API_KEY'),\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    # model=\"bytedance-research/ui-tars-72b:free\",\n",
    "    model=\"google/gemini-2.5-pro-exp-03-25:free\",\n",
    "    extra_headers={\n",
    "        \"HTTP-Referer\": \"binjian.github.io\",\n",
    "        \"X-Title\": \"My Test\",\n",
    "    },\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"给我讲个川普和普京的笑话吧.\"\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ],
   "id": "3ff680b3471679e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好的，这是一个关于川普和普京的笑话：\n",
      "\n",
      "有一天，川普和普京一起在河边钓鱼。\n",
      "\n",
      "川普用的是最高科技的鱼竿，最贵的鱼饵，旁边还放着一个巨大的冷藏箱，他不停地跟普京吹嘘：“弗拉基米尔，你看我这装备，顶级的！绝对能钓上最大的鱼！没有人比我更懂钓鱼，相信我！”\n",
      "\n",
      "普京只是默默地坐在那里，用一根看起来很普通的旧鱼竿，时不时还往河里瞟几眼。\n",
      "\n",
      "过了一会儿，普京一条接一条地钓上大鱼，鱼桶都快满了。而川普那边，浮标动都没动一下。\n",
      "\n",
      "川普气得脸都红了，抱怨道：“这不公平！这绝对是被操控了！这些鱼肯定是假鱼（Fake Fish）！或者是深水州（Deep State\n",
      "）派来的鱼！”\n",
      "\n",
      "普京淡淡地看了他一眼，把一条刚钓上来的大鲈鱼扔进桶里，平静地说：“唐纳德，也许……鱼只是更喜欢那些能安静等待、并且知道在哪里下钩的渔夫？”\n",
      "\n",
      "---\n",
      "**温馨提示：** 这只是一个基于公众人物刻板印象的笑话，目的是为了娱乐，并不代表他们真实的情况或关系。希望你觉得好笑！\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T05:49:19.007969Z",
     "start_time": "2025-04-03T05:49:17.212271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm = OpenRouter(\n",
    "    api_key=os.environ.get('OPENROUTER_API_KEY'),\n",
    "    max_tokens=256,\n",
    "    context_window=4096,\n",
    "    model=\"google/gemma-3-12b-it:free\"\n",
    "    # model=\"google/gemini-2.5-pro-exp-03-25:free\"\n",
    "    # model=\"deepseek/deepseek-r1:free\"\n",
    "    # model=\"gryphe/mythomax-l2-13b:free\"\n",
    ")\n",
    "message = ChatMessage(role=\"user\", content=\"Tell me a joke.\")\n",
    "resp = llm.chat([message])\n",
    "print(resp)"
   ],
   "id": "58185c30e957ddc8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: \n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything! 😂\n",
      "\n",
      "\n",
      "\n",
      "Hope that gave you a chuckle!\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T05:52:35.462713Z",
     "start_time": "2025-04-03T05:52:29.461988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "message = ChatMessage(role=\"user\", content=\"请讲述一个250字的科幻小说故事\")\n",
    "resp = llm.stream_chat([message])\n",
    "for r in resp:\n",
    "    print(r.delta, end='', flush=True)\n"
   ],
   "id": "32993f368452573a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## 遗忘之海\n",
      "\n",
      "**第一章：锈蚀的信号**\n",
      "\n",
      "星历3247年，我，艾瑞斯·科尔，是一名星际考古学家，专门研究失落文明的遗迹。我的飞船“探寻者号”正漂浮在遗忘之海边缘，一个被星际联盟划定为禁区，因为这里充斥着无法解释的能量波动和令人不安的幻觉。\n",
      "\n",
      "遗忘之海，曾经是繁星点点的星域，如今却只剩下一片深邃的黑色，仿佛宇宙本身被撕裂了一道口子。几百年前，一个名为“阿卡迪亚”的文明突然消失于此，留下的只有无尽的黑暗和令人毛骨悚然的传说。\n",
      "\n",
      "我之所以来到这里，是因为收到了一段微弱的信号，一段来自阿卡迪亚文明的求救信号。联盟认为这只是宇宙背景噪音，但我的直觉告诉我，这并非如此。阿卡迪亚文明以其高度发达的科技和对精神领域的探索而闻名，如果他们真的遭遇了什么，那将是足以改变星际历史的事件。\n",
      "\n",
      "“探寻"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T05:55:19.092013Z",
     "start_time": "2025-04-03T05:55:13.094961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resp = llm.complete(\"Tell me a joke in Feynman style.\")\n",
    "print(resp)"
   ],
   "id": "a525dce9e6fa9254",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, here's a joke, explained in a Feynman-esque way. It's not *just* the joke, but the process of getting to the joke, and then a little bit of why it's funny, all laid out like Richard Feynman might have approached it.\n",
      "\n",
      "**(Deep breath, adjusts glasses, leans forward slightly)**\n",
      "\n",
      "Alright, so you know how we talk about probability, right? Like, flipping a coin.  It's supposed to be 50/50, heads or tails.  Simple, right?  But *really*, it's a whole mess of physics going on. You've got the initial force you put on it, the angle, the air resistance, the spin... all these things influencing where it lands.  It's chaotic!  You can't *perfectly* predict it.  That's why we use probability – it's a way of dealing with the fact that we don't know all the details.\n",
      "\n",
      "Now, imagine you're flipping a coin, and you flip it, and it lands on heads.  And you flip it again, and it's heads.  And again... heads.  Five heads in a row.  You\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9745999e02e4dca5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from os import getenv\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "llm = ChatOpenAI(\n",
    "  openai_api_key=getenv(\"OPENROUTER_API_KEY\"),\n",
    "  openai_api_base=getenv(\"OPENROUTER_BASE_URL\"),\n",
    "  model_name=\"<model_name>\",\n",
    "  model_kwargs={\n",
    "    \"headers\": {\n",
    "      \"HTTP-Referer\": getenv(\"YOUR_SITE_URL\"),\n",
    "      \"X-Title\": getenv(\"YOUR_SITE_NAME\"),\n",
    "    }\n",
    "  },\n",
    ")\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "question = \"What NFL team won the Super Bowl in the year Justin Beiber was born?\"\n",
    "print(llm_chain.run(question))"
   ],
   "id": "454611c4239fe93e"
  },
  {
   "cell_type": "code",
   "id": "7fedc9815862b597",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T02:57:06.964894Z",
     "start_time": "2025-04-03T02:56:56.759636Z"
    }
   },
   "source": [
    "message = ChatMessage(role=\"user\", content=\"给我讲个少林寺笑话吧.\")\n",
    "resp = llm.chat(messages=[message])\n",
    "print(resp)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: 好的，我给你讲一个关于少林寺的笑话：\n",
      "\n",
      "---\n",
      "\n",
      "有一天，少林寺的方丈召集众弟子，说：“今天我要考考你们的智慧。我给你们每人一个木鱼，谁能在最短的时间内让木鱼发出声音，谁就能得到奖励。”\n",
      "\n",
      "众弟子一听，纷纷开始想办法。有的弟子把木鱼放在石头上敲，有的弟子用木棍敲，还有的弟子甚至把木鱼扔到地上摔。\n",
      "\n",
      "这时，一个小和尚站了出来，他拿起木鱼，放在耳边，认真地听了一会儿，然后对大家说：“我听到声音了！”\n",
      "\n",
      "众弟子都愣住了，纷纷问：“你怎么听到的？”\n",
      "\n",
      "小和尚得意地说：“很简单啊，我用耳朵听的！”\n",
      "\n",
      "方丈听了，哈哈大笑，说：“你这个小和尚，真是聪明！”\n",
      "\n",
      "---\n",
      "\n",
      "这个笑话虽然简单，但寓意深刻，提醒我们有时候解决问题的方法可能并不复杂，关键在于换个角度思考。希望你喜欢！ 😄\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93763aa0099a0230",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9afffa0b24b89dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233045d32dc09b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "vector_store = InMemoryVectorStore(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139a24da5a1a14cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "import validators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f4d67c64d6c76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Load and chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Index chunks\n",
    "_ = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "# Define prompt for question-answering\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4096eb913c1404ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8083cd73fabb9d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def answer(message, history, system_prompt, tokens):\n",
    "    files = []\n",
    "    file_names = []\n",
    "    for msg in history:\n",
    "        if msg[\"role\"] == \"user\" and isinstance(msg[\"content\"], tuple):\n",
    "            files.append(msg[\"content\"][0])\n",
    "            file_names.append(msg[\"content\"][0].split(\"/\")[-1])\n",
    "    for file in message[\"files\"]:\n",
    "        files.append(file)\n",
    "        file_names.append(file.split(\"/\")[-1])\n",
    "\n",
    "    #if message[\"text\"]:\n",
    "    #    content = message[\"text\"]\n",
    "    #else:\n",
    "    #    content = system_prompt\n",
    "    # content = message\n",
    "    # question = system_prompt\n",
    "    # response = f\"Content: {content}\\nQuestion: {question}\\n\"\n",
    "    # len = min(len(response),int(response_len))\n",
    "\n",
    "    user_input = f\"Question: {system_prompt}\\n Website: {message['text']}\\n File:\\n{'\\n'.join(file_names)}\"\n",
    "\n",
    "    if validators.url(message['text']):\n",
    "        loader = WebBaseLoader(\n",
    "            # web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "            web_paths=(message['text'],),\n",
    "            bs_kwargs=dict(\n",
    "                parse_only=bs4.SoupStrainer(\n",
    "                    class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "                )\n",
    "            ),\n",
    "        )\n",
    "        docs = loader.load()\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "        all_splits = text_splitter.split_documents(docs)\n",
    "        # Index chunks\n",
    "        _ = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "        # # # Compile application and test\n",
    "        # graph_builder_i = StateGraph(State).add_sequence([retrieve, generate])\n",
    "        # graph_builder_i.add_edge(START, \"retrieve\")\n",
    "        # graph_i = graph_builder_i.compile()\n",
    "        reply = graph.invoke({\"question\": system_prompt})\n",
    "        response_i = reply[\"answer\"]\n",
    "    elif files:\n",
    "        f = files[-1]\n",
    "        f_name = file_names[-1]多久维护一次产品?\n",
    "        response_i = f\"File: {f_name}\\n\"\n",
    "\n",
    "    # response_i = user_input\n",
    "    for i in range(min(len(response_i), int(tokens))):\n",
    "        time.sleep(0.05)\n",
    "        yield response_i[: i + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b20e2a1-b622-4970-9069-0202ce10a2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# |export\n",
    "demo = gr.ChatInterface(\n",
    "    answer,\n",
    "    type=\"messages\",\n",
    "    title=\"智能问答RAG\",\n",
    "    description=\"输入一个网址，查询或询问其中的内容。\",\n",
    "    textbox=gr.MultimodalTextbox(value=\"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "                                 file_count=\"multiple\",\n",
    "                                 file_types=[\"image\", \".pdf\", \".txt\"],\n",
    "                                 sources=[\"upload\", \"microphone\"]),\n",
    "    additional_inputs=[\n",
    "        gr.Textbox(\"What is Task Decomposition?\", label=\"你的问题在此输入！\"),\n",
    "        gr.Slider(10,400,value=300,label=\"回答长度\")\n",
    "    ],\n",
    "    multimodal=True,\n",
    ")\n",
    "demo.launch(share=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d7be72-9389-42cf-91b1-78e8f4bbd083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7865\n"
     ]
    }
   ],
   "source": [
    "# this is only necessary in a notebook\n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88424f53-cd78-41fe-9e06-8a6209001064",
   "metadata": {},
   "source": [
    "## Create a `requirements.txt` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4a30aa-9090-460e-acf9-4eb359161125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../requirements.txt\n",
    "fastcore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249b2cd7-3123-45bf-945f-882b8a964cf5",
   "metadata": {},
   "source": [
    "## Convert this notebook into a Gradio app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6706d92c-5785-4f09-9773-b9a944c493a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nbdev.export import nb_export\n",
    "# nb_export('01_gradio.ipynb', lib_path='.', name='gradio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c0f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0182403f-d1d6-48c0-8e66-46aefb23a9ab",
   "metadata": {},
   "source": [
    "<div>\n",
    "<link rel=\"stylesheet\" href=\"https://gradio.s3-us-west-2.amazonaws.com/2.6.5/static/bundle.css\">\n",
    "<div id=\"target\"></div>\n",
    "<script src=\"https://gradio.s3-us-west-2.amazonaws.com/2.6.5/static/bundle.js\"></script>\n",
    "<script>\n",
    "launchGradioFromSpaces(\"abidlabs/question-answering\", \"#target\")\n",
    "</script>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
