{
 "cells": [
  {
   "cell_type": "raw",
   "id": "2919343d",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "output-file: langchain_rag.html\n",
    "title: Gradio RAG tutorial with langchain\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "id": "68340256",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T06:35:06.189840Z",
     "start_time": "2025-03-27T06:35:06.185212Z"
    }
   },
   "source": "# |default_exp langchain_rag",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "15fe30a9-cfeb-4ec0-ae40-334072046464",
   "metadata": {},
   "source": [
    "Please reference [this blog post](https://nbdev.fast.ai/blog/posts/2022-11-07-spaces) on how to use this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf7644f-42b3-4d8d-a1d0-f8c3a2358e27",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca22d1e-1bd0-49c0-9b89-c480ad1a29c4",
   "metadata": {},
   "source": [
    "## Make an app with Gradio"
   ]
  },
  {
   "cell_type": "code",
   "id": "00cf4fad-a920-41dc-be42-3992c7fcefac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T06:35:07.883320Z",
     "start_time": "2025-03-27T06:35:06.231358Z"
    }
   },
   "source": [
    "# |export\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T06:35:08.823506Z",
     "start_time": "2025-03-27T06:35:07.954302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#| export\n",
    "from langchain_openai import ChatOpenAI\n",
    "import getpass\n"
   ],
   "id": "1cc7c77a267305b2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "9167da2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T06:37:53.629560Z",
     "start_time": "2025-03-27T06:37:53.621063Z"
    }
   },
   "source": [
    "# |export\n",
    "load_dotenv()\n",
    "os.environ['HTTP_PROXY'] = ''\n",
    "os.environ['HTTPS_PROXY'] = ''\n",
    "os.environ['NO_PROXY'] = 'localhost, 127.0.0.1'\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T06:35:08.926469Z",
     "start_time": "2025-03-27T06:35:08.922438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(os.environ.get('OPENAI_API_KEY'))\n",
    "print(os.environ.get('LANGSMITH_API_KEY'))\n",
    "print(os.environ.get('LANGSMITH_PROJECT'))\n",
    "print(os.environ.get('USER_AGENT'))\n",
    "\n"
   ],
   "id": "1b77db9df3d720ca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n",
      "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\n",
      "pr-mundane-artist-14\n",
      "langsmith_rag_tutorial/0.1.0\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T06:35:09.014223Z",
     "start_time": "2025-03-27T06:35:09.010075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#llm = ChatOpenAI()\n",
    "#llm.invoke(\"Hello, world!\")"
   ],
   "id": "7fedc9815862b597",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T06:35:09.117260Z",
     "start_time": "2025-03-27T06:35:09.062105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#| export\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ],
   "id": "93763aa0099a0230",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T06:35:09.176889Z",
     "start_time": "2025-03-27T06:35:09.128209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ],
   "id": "f9afffa0b24b89dd",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T06:35:09.191598Z",
     "start_time": "2025-03-27T06:35:09.188861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#| export\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "vector_store = InMemoryVectorStore(embeddings)\n"
   ],
   "id": "233045d32dc09b74",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T06:35:11.868579Z",
     "start_time": "2025-03-27T06:35:11.752167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#| export\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict"
   ],
   "id": "139a24da5a1a14cf",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T06:53:14.831074Z",
     "start_time": "2025-03-27T06:53:07.336006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#| export\n",
    "# Load and chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Index chunks\n",
    "_ = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "# Define prompt for question-answering\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ],
   "id": "69f4d67c64d6c76a",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T06:35:26.454781Z",
     "start_time": "2025-03-27T06:35:26.447234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#| export\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ],
   "id": "4096eb913c1404ef",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T06:35:34.372005Z",
     "start_time": "2025-03-27T06:35:30.212260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
    "print(response[\"answer\"])"
   ],
   "id": "22a2b3cf01b2fc55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task decomposition is the process of breaking down a complex task into smaller, manageable steps or subgoals. This can be achieved through techniques like Chain of Thought (CoT), which encourages the model to think step-by-step, or by creating a Tree of Thoughts that explores multiple reasoning possibilities for each step. It can be initiated through simple prompts, specific instructions, or human inputs.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T07:00:40.643258Z",
     "start_time": "2025-03-27T07:00:40.638144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#| export\n",
    "def answer(message, history, system_prompt, tokens):\n",
    "    files = []\n",
    "    file_names = []\n",
    "    for msg in history:\n",
    "        if msg[\"role\"] == \"user\" and isinstance(msg[\"content\"], tuple):\n",
    "            files.append(msg[\"content\"][0])\n",
    "            file_names.append(msg[\"content\"][0].split(\"/\")[-1])\n",
    "    for file in message[\"files\"]:\n",
    "        files.append(file)\n",
    "        file_names.append(file.split(\"/\")[-1])\n",
    "\n",
    "    #if message[\"text\"]:\n",
    "    #    content = message[\"text\"]\n",
    "    #else:\n",
    "    #    content = system_prompt\n",
    "    # content = message\n",
    "    # question = system_prompt\n",
    "    # response = f\"Content: {content}\\nQuestion: {question}\\n\"\n",
    "    # len = min(len(response),int(response_len))\n",
    "\n",
    "    user_input = f\"Question: {system_prompt}\\n Website: {message['text']}\\n File:\\n{'\\n'.join(file_names)}\"\n",
    "\n",
    "\n",
    "    loader = WebBaseLoader(\n",
    "        # web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "        web_paths=(message['text'],),\n",
    "        bs_kwargs=dict(\n",
    "            parse_only=bs4.SoupStrainer(\n",
    "                class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "    docs = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    all_splits = text_splitter.split_documents(docs)\n",
    "    # Index chunks\n",
    "    _ = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "    # # # Compile application and test\n",
    "    # graph_builder_i = StateGraph(State).add_sequence([retrieve, generate])\n",
    "    # graph_builder_i.add_edge(START, \"retrieve\")\n",
    "    # graph_i = graph_builder_i.compile()\n",
    "    reply = graph.invoke({\"question\": system_prompt})\n",
    "    response_i = reply[\"answer\"]\n",
    "\n",
    "    # response_i = user_input\n",
    "    for i in range(min(len(response_i), int(tokens))):\n",
    "        time.sleep(0.05)\n",
    "        yield response_i[: i + 1]"
   ],
   "id": "8083cd73fabb9d13",
   "outputs": [],
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "id": "7b20e2a1-b622-4970-9069-0202ce10a2ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T07:00:45.458862Z",
     "start_time": "2025-03-27T07:00:44.903881Z"
    }
   },
   "source": [
    "# |export\n",
    "demo = gr.ChatInterface(\n",
    "    answer,\n",
    "    type=\"messages\",\n",
    "    title=\"智能问答RAG\",\n",
    "    description=\"输入一个网址，查询或询问其中的内容。\",\n",
    "    textbox=gr.MultimodalTextbox(value=\"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "                                 file_count=\"multiple\",\n",
    "                                 file_types=[\"image\", \".pdf\", \".txt\"],\n",
    "                                 sources=[\"upload\", \"microphone\"]),\n",
    "    additional_inputs=[\n",
    "        gr.Textbox(\"What is Task Decomposition?\", label=\"你的问题在此输入！\"),\n",
    "        gr.Slider(10,400,value=300,label=\"回答长度\")\n",
    "    ],\n",
    "    multimodal=True,\n",
    ")\n",
    "demo.launch(share=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T07:00:08.588134Z",
     "start_time": "2025-03-27T07:00:08.384064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# this is only necessary in a notebook\n",
    "demo.close()"
   ],
   "id": "39d7be72-9389-42cf-91b1-78e8f4bbd083",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7865\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "cell_type": "markdown",
   "id": "88424f53-cd78-41fe-9e06-8a6209001064",
   "metadata": {},
   "source": [
    "## Create a `requirements.txt` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db4a30aa-9090-460e-acf9-4eb359161125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../requirements.txt\n",
    "fastcore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249b2cd7-3123-45bf-945f-882b8a964cf5",
   "metadata": {},
   "source": [
    "## Convert this notebook into a Gradio app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6706d92c-5785-4f09-9773-b9a944c493a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nbdev.export import nb_export\n",
    "# nb_export('01_gradio.ipynb', lib_path='.', name='gradio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c0f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0182403f-d1d6-48c0-8e66-46aefb23a9ab",
   "metadata": {},
   "source": [
    "<div>\n",
    "<link rel=\"stylesheet\" href=\"https://gradio.s3-us-west-2.amazonaws.com/2.6.5/static/bundle.css\">\n",
    "<div id=\"target\"></div>\n",
    "<script src=\"https://gradio.s3-us-west-2.amazonaws.com/2.6.5/static/bundle.js\"></script>\n",
    "<script>\n",
    "launchGradioFromSpaces(\"abidlabs/question-answering\", \"#target\")\n",
    "</script>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
