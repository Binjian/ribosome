{
 "cells": [
  {
   "cell_type": "raw",
   "id": "2919343d",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: llama_index_mcp.html\n",
    "title: MCP tutorial with llama_index\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68340256",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T03:36:20.118298Z",
     "start_time": "2025-05-06T03:36:20.116957Z"
    }
   },
   "outputs": [],
   "source": [
    "# |default_exp llama_index_mcp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf7644f-42b3-4d8d-a1d0-f8c3a2358e27",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cf4fad-a920-41dc-be42-3992c7fcefac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "import gradio as gr\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7670bb0b",
   "metadata": {},
   "source": [
    "This is a simple RAG chatbot built on top of Llama Index and Gradio. It allows you to upload any text or PDF files and ask questions about them!\n",
    "Before running this, make sure you have exported your OpenAI API key as an environment variable:\n",
    "\n",
    "```bash\n",
    "export OPENAI_API_KEY=\"mykey\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9167da2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb99867",
   "metadata": {},
   "outputs": [],
   "source": [
    "oai_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "print(oai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a4389f-ef53-4626-a6f5-a859354f854b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "def answer(message, history):\n",
    "    files = []\n",
    "    for msg in history:\n",
    "        if msg[\"role\"] == \"user\" and isinstance(msg[\"content\"], tuple):\n",
    "            files.append(msg[\"content\"][0])\n",
    "    for file in message[\"files\"]:\n",
    "        files.append(file)\n",
    "\n",
    "    documents = SimpleDirectoryReader(input_files=files).load_data()\n",
    "    index = VectorStoreIndex.from_documents(documents)\n",
    "    query_engine = index.as_query_engine()\n",
    "    return str(query_engine.query(message[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65daf0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $HF_ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bc32b8-d8ff-4761-a2d7-0880c51d0a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "demo = gr.ChatInterface(\n",
    "    answer,\n",
    "    type=\"messages\",\n",
    "    title=\"Llama Index RAG Chatbot\",\n",
    "    description=\"Upload any text or pdf files and ask questions about them!\",\n",
    "    textbox=gr.MultimodalTextbox(file_types=[\".pdf\", \".txt\"]),\n",
    "    multimodal=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b20e2a1-b622-4970-9069-0202ce10a2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d7be72-9389-42cf-91b1-78e8f4bbd083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is only necessary in a notebook\n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88424f53-cd78-41fe-9e06-8a6209001064",
   "metadata": {},
   "source": [
    "## Create a `requirements.txt` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4a30aa-9090-460e-acf9-4eb359161125",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../requirements.txt\n",
    "fastcore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249b2cd7-3123-45bf-945f-882b8a964cf5",
   "metadata": {},
   "source": [
    "## Convert this notebook into a Gradio app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6706d92c-5785-4f09-9773-b9a944c493a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nbdev.export import nb_export\n",
    "# nb_export('01_gradio.ipynb', lib_path='.', name='gradio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c0f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0182403f-d1d6-48c0-8e66-46aefb23a9ab",
   "metadata": {},
   "source": [
    "<div>\n",
    "<link rel=\"stylesheet\" href=\"https://gradio.s3-us-west-2.amazonaws.com/2.6.5/static/bundle.css\">\n",
    "<div id=\"target\"></div>\n",
    "<script src=\"https://gradio.s3-us-west-2.amazonaws.com/2.6.5/static/bundle.js\"></script>\n",
    "<script>\n",
    "launchGradioFromSpaces(\"abidlabs/question-answering\", \"#target\")\n",
    "</script>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
