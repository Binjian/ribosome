{
 "cells": [
  {
   "cell_type": "raw",
   "id": "4bd68effe0fec893",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: rag.html\n",
    "title: rag tutorial\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a7d3fa89528e4f",
   "metadata": {},
   "outputs": [],
   "source": "# |default_exp rag"
  },
  {
   "cell_type": "markdown",
   "id": "40bae3045488c83c",
   "metadata": {},
   "source": "## Install dependencies"
  },
  {
   "cell_type": "markdown",
   "id": "8689e7841c3c3942",
   "metadata": {},
   "source": "## Make an app with Gradio"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ed1a604344bdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# |export\n",
    "import ollama\n",
    "import re\n",
    "import gradio as gr\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from chromadb.config import Settings\n",
    "from chromadb import Client\n",
    "import chromadb\n",
    "from langchain.vectorstores import Chroma\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import csv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from fastcore.net import urljson, HTTPError\n",
    "from openai import api_key\n",
    "from openai import OpenAI\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dbf8f53e3c0074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "import textwrap\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "from IPython.display import Markdown\n",
    "import langdetect\n",
    "# import chromadb.utils.embedding_functions as embedding_functions\n",
    "# from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b9711b97c3badd",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "# deepseek_key = os.getenv('DEEPSEEK_R1_bAPI_KEY')\n",
    "gemini_key = os.getenv('GEMINI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93216319d0c451ff",
   "metadata": {},
   "outputs": [],
   "source": "print(os.environ.get('HTTPS_PROXY'))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aac6dbc5a649418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "requests.get(\"https://google.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f542994eda15019",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(api_key=gemini_key,\n",
    "                      http_options={'api_version': 'v1beta'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9a82a28b0b47c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = client.models.list()\n",
    "for m in all_models.page:\n",
    "    if 'embedContent' in m.supported_actions:\n",
    "        print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b2bc63bd67f6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        model = \"models/text-embedding-004\"\n",
    "        # model = \"models/gemini-embedding-exp-03-07\"\n",
    "        # model = \"models/text-embedding-001\"\n",
    "        # model = \"text-multilingual-embedding-002\"\n",
    "        # title = \"Siasun Employee Manual query\"\n",
    "        result = client.models.embed_content(model=model,\n",
    "                                   contents=input,\n",
    "                                   config=types.EmbedContentConfig(task_type='SEMANTIC_SIMILARITY'),\n",
    "                                   # config=types.EmbedContentConfig(task_type='RETRIEVAL_DOCUMENT'),\n",
    "                                   )\n",
    "        return result.embeddings[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f24df6ec25ad94f",
   "metadata": {},
   "outputs": [],
   "source": "'p'+str(1)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d189a8231ac5389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_chroma_db(documents, name, language='en'):\n",
    "    chroma_client = chromadb.PersistentClient(path=\"../db\")\n",
    "    # chroma_client = chromadb.Client()\n",
    "    if language == 'en':\n",
    "        coll = chroma_client.get_or_create_collection(name=name,\n",
    "                                                    embedding_function=GeminiEmbeddingFunction(),\n",
    "                                                      metadata={\n",
    "                                                          \"description\": name,\n",
    "                                                          \"created_by\": \"binjian\",\n",
    "                                                          \"created\": str(datetime.now())\n",
    "                                                      })\n",
    "    else: # use default\n",
    "        coll = chroma_client.get_or_create_collection(name=name,\n",
    "                                                      metadata={\n",
    "                                                          \"description\": name,\n",
    "                                                          \"created_by\": \"binjian\",\n",
    "                                                          \"created\": str(datetime.now())\n",
    "                                                      })\n",
    "    # coll.add(\n",
    "    #     documents=[d.page_content for d in documents],\n",
    "    #     metadatas=[d.metadata for d in documents],\n",
    "    #     ids=['p'+str(i+1) for i in range(len(documents))]\n",
    "    # )\n",
    "    # return coll\n",
    "    for i,d  in enumerate(documents):\n",
    "         try:\n",
    "             coll.add(\n",
    "                 documents=d.page_content,\n",
    "                 metadatas=d.metadata,\n",
    "                 ids=str(i+1)\n",
    "             )\n",
    "             print(f\"Added document {i+1}\")\n",
    "         except Exception as e:\n",
    "             print(f\"{i+1},{e}\")\n",
    "\n",
    "    return coll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee088ba496424b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "loader = PyMuPDFLoader(\"../res/DeepSeek_R1.pdf\")\n",
    "# loader = PyMuPDFLoader(\"../res/employee_manual.pdf\")\n",
    "documents = loader.load()\n",
    "docs = [d.page_content for d in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c52eec9d9cda5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def select_embedding_model(input_text):\n",
    "    try:\n",
    "        language = langdetect.detect(input_text)\n",
    "        print(language)\n",
    "    except langdetect.LangDetectException:\n",
    "        language = None\n",
    "        print(\"Language detection failed. Please use default model!\")\n",
    "    return language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84321e0fd2cf574b",
   "metadata": {},
   "outputs": [],
   "source": "lang = select_embedding_model(docs[-1])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff434304ac5fe8dc",
   "metadata": {},
   "outputs": [],
   "source": "client"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0672146eefca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if lang == 'en':\n",
    "    result = client.models.embed_content(model=\"models/gemini-embedding-exp-03-07\",\n",
    "        # model=\"text-embedding-004\",\n",
    "        contents=documents[0].page_content,\n",
    "        config=types.EmbedContentConfig(task_type='SEMANTIC_SIMILARITY')\n",
    "    )\n",
    "else:\n",
    "    result = client.models.embed_content(model=\"models/embedding-001\",\n",
    "        contents=documents[0].page_content,\n",
    "        config=types.EmbedContentConfig(task_type='SEMANTIC_SIMILARITY')\n",
    "    )\n",
    "    print(\"select Multilingual\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eb63a6efaddc16",
   "metadata": {},
   "outputs": [],
   "source": "result.embeddings[0].values"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a00edae7597f40b",
   "metadata": {},
   "outputs": [],
   "source": "lang"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7d4bea6d6d8d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# db = create_chroma_db(documents, \"employee_manual\", language=lang)\n",
    "db = create_chroma_db(documents, \"deepseek_r1\")\n",
    "# chroma_client = chromadb.PersistentClient(path=\"../db\")\n",
    "# db = chroma_client.get_or_create_collection('deepseek_r1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db6f136a0ea2af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chroma_client = chromadb.PersistentClient(path=\"../db\")\n",
    "# chroma_client.delete_collection(name='deepseek_r1')\n",
    "chroma_client.list_collections()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ab8a24de9976a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chroma_client = chromadb.Client()\n",
    "recs = db.peek(5)\n",
    "# df = pd.DataFrame(recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d647e4f8f58304f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_passage(query, db):\n",
    "    passage = db.query(query_texts=[query], n_results=1)['documents'][0][0]\n",
    "    return passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c2a68493cb7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform embedding search\n",
    "passage = get_relevant_passage(\"How does the distilled models perform in evaluation comparing to other models?\", db)\n",
    "# passage = get_relevant_passage(\"休假规定\", db)\n",
    "Markdown(passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5246fdba83888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(query, relevant_passage):\n",
    "    escaped = relevant_passage.replace(\"'\", \"\").replace('\"', \"\").replace(\"\\n\", \" \")\n",
    "    prompt = (\"\"\"You are a helpful and informative bot that answers questions using text from the reference passage included below. \\\n",
    "    Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \\\n",
    "    However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \\\n",
    "    strike a friendly and converstional tone. \\\n",
    "    If the passage is irrelevant to the answer, you may ignore it. \\\n",
    "    Please answer in Chinese.\n",
    "    QUESTION: '{query}'\n",
    "    PASSAGE: '{relevant_passage}'\n",
    "\n",
    "        ANSWER:\n",
    "    \"\"\").format(query=query, relevant_passage=escaped)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b322ff6b274d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query =\"How does the distilled models perform in evaluation comparing to other models?\"\n",
    "query =\"这里的蒸馏模型在评估中的表现和其他模型比较的结果如何?\"\n",
    "prompt = make_prompt(query, passage)\n",
    "Markdown(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae93ff6b9a61d7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = genai.Client(api_key=gemini_key)\n",
    "# response = client.models.generate_content(model=\"gemini-2.0-flash\", contents=prompt)\n",
    "response = client.models.generate_content(model=\"gemini-2.5-pro-exp-03-25\", contents=prompt)\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7b98c3785bb533",
   "metadata": {},
   "outputs": [],
   "source": "Markdown(response.text)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee657b91ee63efc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the document into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696557bdaac4d522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding = client.embeddings.create(\n",
    "#         model=\"deepseek/deepseek-r1:free\",\n",
    "#         input='Your text string goes here'\n",
    "#     )\n",
    "# embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e691b9105f92f799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallelize embedding generation\n",
    "def generate_embedding(chunk):\n",
    "    # return ollama_embedding_function.embed_query(chunk.page_content)\n",
    "    return google_ef.embed_query(chunk.page_content)\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    embeddings = list(executor.map(generate_embedding, chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aab85556fd1c15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "completion = client.chat.completions.create(\n",
    "  extra_headers={\n",
    "    \"HTTP-Referer\": \"binjian.github.io\", # Optional. Site URL for rankings on openrouter.ai.\n",
    "    \"X-Title\": \"binjian's digital garden\", # Optional. Site title for rankings on openrouter.ai.\n",
    "  },\n",
    "  extra_body={},\n",
    "  model=\"deepseek/deepseek-r1:free\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\", \"content\": \"You are a helpful assistant.\",\n",
    "      \"role\": \"user\", \"content\": \"What's Anthropic's Model context protocol?\"\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81899cd24437f8e",
   "metadata": {},
   "outputs": [],
   "source": "google_ef = embedding_functions.GoogleGenerativeAiEmbeddingFunction(api_key=gemini_key)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a4709412146528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_qa_to_csv(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Convert a text file with Q/A format to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        input_file: Path to the input text file\n",
    "        output_file: Path to the output CSV file\n",
    "    \"\"\"\n",
    "    # Read the content of the file\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # Split the content by 'Q' marker\n",
    "    qa_blocks = content.split('Q\\n')\n",
    "\n",
    "    qa_blks = [block.strip() for block in qa_blocks][1:]\n",
    "    # Remove empty blocks (like the first one if file starts with 'Q')\n",
    "    # qa_blocks = [[line for line in block.split('\\n') ] for block in qa_blks if block.strip()]\n",
    "    # Remove empty blocks (like the first one if file starts with 'Q')\n",
    "    # qa_blocks = [blk for block in qa_blocks if block.strip() for blk in block.strip()]\n",
    "\n",
    "    # Process each Q&A block\n",
    "    qa_pairs = []\n",
    "    for block in qa_blks:\n",
    "        # Split the block into lines\n",
    "        lines = block.strip().split('\\n')\n",
    "\n",
    "        if lines:\n",
    "            # First line is the question\n",
    "            question = lines[0]\n",
    "            # The rest are the answer\n",
    "            answer = '\\n'.join(lines[1:])\n",
    "\n",
    "            # Add the pair to our list\n",
    "            qa_pairs.append([question, answer])\n",
    "\n",
    "    # Write to CSV\n",
    "    with open(output_file, 'w', encoding='utf-8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        # Write header\n",
    "        writer.writerow(['Question', 'Answer'])\n",
    "        # Write Q&A pairs\n",
    "        for pair in qa_pairs:\n",
    "            writer.writerow(pair)\n",
    "    print(f\"Conversion complete. CSV file saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b867632cd7164a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_files = [\"../res/qa_service.txt\", \"../res/qa_technology.txt\"]\n",
    "output_files = [\"../res/qa_service.csv\", \"../res/qa_technology.csv\"]\n",
    "for in_f, ot_f in zip(input_files, output_files):\n",
    "    convert_qa_to_csv(in_f, ot_f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87d7540e3a1b0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "client = chromadb.PersistentClient(path=\"../vdb\")\n",
    "# collections = [client.get_or_create_collection(name=\"siasun_qa_service\",embedding_function=deepseek_ef),\n",
    "#                 client.get_or_create_collection(name=\"siasun_qa_technology\",embedding_function=deepseek_ef)]\n",
    "collections = [client.get_or_create_collection(name=\"siasun_qa_service\", embedding_function=google_ef),\n",
    "                client.get_or_create_collection(name=\"siasun_qa_technology\", embedding_function=google_ef)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c4e9c21acabd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=2\n",
    "f'q{i}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8cffa926183329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "for csv_file,collection in zip(output_files,collections):\n",
    "    with open(csv_file, newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for i, row in enumerate(reader):\n",
    "            collection.add(\n",
    "                documents = row,\n",
    "                metadatas = [{\"source\": \"question\"}, {\"source\": \"answer\"}],\n",
    "                ids = [f\"{collection.name}_q{i}\", f\"{collection.name}_a{i}\"]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f314ee21cd5cd18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "queries=[\"你们的产品需要多久维护一次?\",\"我怎么设置机器人的安全工作区域?\"]\n",
    "queries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d885aba898533f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collections[0].query(\n",
    "    query_texts=queries,\n",
    "    n_results=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da70193ed6f00208",
   "metadata": {},
   "outputs": [],
   "source": "results"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a9c1661db02f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results['metadatas'][0] #[0]['source']\n",
    "results['documents'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d6a395a5b7a803",
   "metadata": {},
   "outputs": [],
   "source": [
    "colls = client.list_collections()\n",
    "colls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1332f82fbe473593",
   "metadata": {},
   "outputs": [],
   "source": "queries1 = ['你们的产品需要多久维护一次?','宏作业有什么用?']"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80b1495078948f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = collections[0].query(\n",
    "    query_texts=queries1,\n",
    "    n_results=4\n",
    ")\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b73eb7792be2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# question = \"你们的产品需要多久维护一次?\"\n",
    "# question = \"你们在售前评估上，如何帮助到我们?\"\n",
    "answers = []\n",
    "for collection in collections:\n",
    "    results = collection.query(\n",
    "        query_texts=queries,\n",
    "        n_results=4\n",
    "    )\n",
    "    docs = []\n",
    "    for i,metadata in enumerate(results['metadatas'][0]):\n",
    "        if metadata['source'] == 'question':\n",
    "            docs.append({'id': results['ids'][0][i],\n",
    "                         'document': results['documents'][0][i],\n",
    "                         'distance':results['distances'][0][i]})\n",
    "    df = pd.DataFrame(docs)\n",
    "    answers.append(df)\n",
    "df_answers = pd.concat(answers, axis=0,ignore_index=True)\n",
    "# df_answers = pd.stack(answers, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58ee1e3e4554ea0",
   "metadata": {},
   "outputs": [],
   "source": "df_answers.loc[df_answers['distance'].idxmin()]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622e9f7c853af379",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "id_q = df_answers.loc[df_answers['distance'].idxmin()]['id']\n",
    "id_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5929799653473da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "id_a_list = id_q.split('_')\n",
    "id_a_list[-1] = id_a_list[-1].replace('q','a')\n",
    "id_a_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a65db8201c85e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_a = '_'.join(id_a_list)\n",
    "id_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3b099a6b99bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_idx = 0 if id_a_list[-2] == 'service' else 1\n",
    "coll_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a710916272b975",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = collections[coll_idx].get(id_a)\n",
    "answer['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d82892da75b95cb",
   "metadata": {},
   "outputs": [],
   "source": "best_answer = df_answers.loc[df_answers['distance'].idxmin()]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea352cd4183e359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa(questions:list[str], collections:list[chromadb.Collection]=collections):\n",
    "    matched_questions = []\n",
    "    for collection in collections:\n",
    "        results = collection.query(\n",
    "            query_texts=questions,\n",
    "            n_results=4\n",
    "        )\n",
    "        docs = []\n",
    "        for i,metadata in enumerate(results['metadatas'][0]):\n",
    "            if metadata['source'] == 'question':\n",
    "                docs.append({'id': results['ids'][0][i],\n",
    "                                'document': results['documents'][0][i], \n",
    "                                'distance':results['distances'][0][i]})\n",
    "        df = pd.DataFrame(docs)\n",
    "        matched_questions.append(df)\n",
    "\n",
    "    df_matched_questions = pd.concat(matched_questions,axis=0,ignore_index=True)\n",
    "    best_match_q_id = df_matched_questions.loc[df_matched_questions['distance'].idxmin()]['id']\n",
    "    id_a_list = best_match_q_id.split('_')\n",
    "    id_a_list[-1] = id_a_list[-1].replace('q','a')\n",
    "    id_a = '_'.join(id_a_list)\n",
    "    coll_idx = 0 if id_a_list[-2] == 'service' else 1\n",
    "    best_answer = collections[coll_idx].get(id_a)['documents']\n",
    "    res_text = best_answer[0]\n",
    "    return res_text\n",
    "    # question =\n",
    "    # return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f749d9cc9a401a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "question = \"你们的产品需要多久维护一次?\"\n",
    "res = qa(question)\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b2f84aa0784af1",
   "metadata": {},
   "outputs": [],
   "source": "print(res[0])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2f204e6ab55bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "iface = gr.Interface(fn=qa, inputs=gr.Text(value=\"多久维护一次产品?\"), outputs=\"text\")\n",
    "iface.launch(width=500,share=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888b1b0530808ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is only necessary in a notebook\n",
    "iface.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc11529d1b85a84",
   "metadata": {},
   "source": "## Create a `requirements.txt` file"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39a06f76c3da0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../requirements.txt\n",
    "fastcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df14eac7a58493f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648dc291964559de",
   "metadata": {},
   "outputs": [],
   "source": "# |default_exp data_preprocessing"
  },
  {
   "cell_type": "markdown",
   "id": "4755b2e93c82953c",
   "metadata": {},
   "source": "## Convert this notebook into a Gradio app"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9549f5fd490578dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nbdev.export import nb_export\n",
    "# nb_export('01_gradio.ipynb', lib_path='.', name='gradio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6118d49775df611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
