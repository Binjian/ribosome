{
 "cells": [
  {
   "cell_type": "raw",
   "id": "4bd68effe0fec893",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: rag.html\n",
    "title: rag tutorial\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a7d3fa89528e4f",
   "metadata": {},
   "outputs": [],
   "source": "# |default_exp rag"
  },
  {
   "cell_type": "markdown",
   "id": "40bae3045488c83c",
   "metadata": {},
   "source": "## Install dependencies"
  },
  {
   "cell_type": "markdown",
   "id": "8689e7841c3c3942",
   "metadata": {},
   "source": "## Make an app with Gradio"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ed1a604344bdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# |export\n",
    "import ollama\n",
    "import re\n",
    "import gradio as gr\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from chromadb.config import Settings\n",
    "from chromadb import Client\n",
    "import chromadb\n",
    "from langchain.vectorstores import Chroma\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import csv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from fastcore.net import urljson, HTTPError\n",
    "from openai import api_key\n",
    "from openai import OpenAI\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dbf8f53e3c0074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "import textwrap\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "from IPython.display import Markdown\n",
    "import langdetect\n",
    "# import chromadb.utils.embedding_functions as embedding_functions\n",
    "# from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b9711b97c3badd",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "# deepseek_key = os.getenv('DEEPSEEK_R1_bAPI_KEY')\n",
    "gemini_key = os.getenv('GEMINI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93216319d0c451ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:20171\n"
     ]
    }
   ],
   "source": "print(os.environ.get('HTTPS_PROXY'))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aac6dbc5a649418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "requests.get(\"https://google.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f542994eda15019",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(api_key=gemini_key,\n",
    "                      http_options={'api_version': 'v1beta'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9a82a28b0b47c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n"
     ]
    }
   ],
   "source": [
    "all_models = client.models.list()\n",
    "for m in all_models.page:\n",
    "    if 'embedContent' in m.supported_actions:\n",
    "        print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b2bc63bd67f6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        model = \"models/text-embedding-004\"\n",
    "        # model = \"models/gemini-embedding-exp-03-07\"\n",
    "        # model = \"models/text-embedding-001\"\n",
    "        # model = \"text-multilingual-embedding-002\"\n",
    "        # title = \"Siasun Employee Manual query\"\n",
    "        result = client.models.embed_content(model=model,\n",
    "                                   contents=input,\n",
    "                                   config=types.EmbedContentConfig(task_type='SEMANTIC_SIMILARITY'),\n",
    "                                   # config=types.EmbedContentConfig(task_type='RETRIEVAL_DOCUMENT'),\n",
    "                                   )\n",
    "        return result.embeddings[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f24df6ec25ad94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p1'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "'p'+str(1)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d189a8231ac5389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_chroma_db(documents, name, language='en'):\n",
    "    chroma_client = chromadb.PersistentClient(path=\"../db\")\n",
    "    # chroma_client = chromadb.Client()\n",
    "    if language == 'en':\n",
    "        coll = chroma_client.get_or_create_collection(name=name,\n",
    "                                                    embedding_function=GeminiEmbeddingFunction(),\n",
    "                                                      metadata={\n",
    "                                                          \"description\": name,\n",
    "                                                          \"created_by\": \"binjian\",\n",
    "                                                          \"created\": str(datetime.now())\n",
    "                                                      })\n",
    "    else: # use default\n",
    "        coll = chroma_client.get_or_create_collection(name=name,\n",
    "                                                      metadata={\n",
    "                                                          \"description\": name,\n",
    "                                                          \"created_by\": \"binjian\",\n",
    "                                                          \"created\": str(datetime.now())\n",
    "                                                      })\n",
    "    # coll.add(\n",
    "    #     documents=[d.page_content for d in documents],\n",
    "    #     metadatas=[d.metadata for d in documents],\n",
    "    #     ids=['p'+str(i+1) for i in range(len(documents))]\n",
    "    # )\n",
    "    # return coll\n",
    "    for i,d  in enumerate(documents):\n",
    "         try:\n",
    "             coll.add(\n",
    "                 documents=d.page_content,\n",
    "                 metadatas=d.metadata,\n",
    "                 ids=str(i+1)\n",
    "             )\n",
    "             print(f\"Added document {i+1}\")\n",
    "         except Exception as e:\n",
    "             print(f\"{i+1},{e}\")\n",
    "\n",
    "    return coll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee088ba496424b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "loader = PyMuPDFLoader(\"../res/DeepSeek_R1.pdf\")\n",
    "# loader = PyMuPDFLoader(\"../res/employee_manual.pdf\")\n",
    "documents = loader.load()\n",
    "docs = [d.page_content for d in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c52eec9d9cda5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def select_embedding_model(input_text):\n",
    "    try:\n",
    "        language = langdetect.detect(input_text)\n",
    "        print(language)\n",
    "    except langdetect.LangDetectException:\n",
    "        language = None\n",
    "        print(\"Language detection failed. Please use default model!\")\n",
    "    return language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84321e0fd2cf574b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en\n"
     ]
    }
   ],
   "source": "lang = select_embedding_model(docs[-1])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff434304ac5fe8dc",
   "metadata": {},
   "outputs": [],
   "source": "client"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0672146eefca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if lang == 'en':\n",
    "    result = client.models.embed_content(model=\"models/gemini-embedding-exp-03-07\",\n",
    "        # model=\"text-embedding-004\",\n",
    "        contents=documents[0].page_content,\n",
    "        config=types.EmbedContentConfig(task_type='SEMANTIC_SIMILARITY')\n",
    "    )\n",
    "else:\n",
    "    result = client.models.embed_content(model=\"models/embedding-001\",\n",
    "        contents=documents[0].page_content,\n",
    "        config=types.EmbedContentConfig(task_type='SEMANTIC_SIMILARITY')\n",
    "    )\n",
    "    print(\"select Multilingual\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eb63a6efaddc16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03420316,\n",
       " -0.058023084,\n",
       " -0.01379631,\n",
       " -0.053755973,\n",
       " 0.055795178,\n",
       " 0.00229457,\n",
       " 0.0034859658,\n",
       " -0.042482354,\n",
       " 0.014814996,\n",
       " -0.002810338,\n",
       " 0.02999089,\n",
       " 0.0065631936,\n",
       " -0.02319022,\n",
       " -0.027307784,\n",
       " 0.004425951,\n",
       " -0.018839397,\n",
       " 0.0075919717,\n",
       " 0.00734865,\n",
       " 0.023094485,\n",
       " 0.013960972,\n",
       " -0.019861953,\n",
       " 0.021044878,\n",
       " -0.027480055,\n",
       " -0.0048022605,\n",
       " -0.029109143,\n",
       " -0.02495774,\n",
       " 0.007414238,\n",
       " -0.04713037,\n",
       " -0.03839761,\n",
       " 0.060691025,\n",
       " -0.084387675,\n",
       " 0.06916909,\n",
       " -0.098064505,\n",
       " -0.016970992,\n",
       " 0.020929338,\n",
       " -0.027915815,\n",
       " -0.0023113044,\n",
       " -0.017437562,\n",
       " -0.007702603,\n",
       " 0.06309596,\n",
       " 0.022029292,\n",
       " 0.019606069,\n",
       " -0.017604707,\n",
       " -0.07957115,\n",
       " 0.024590215,\n",
       " 0.018233163,\n",
       " 0.0025723032,\n",
       " -0.05061143,\n",
       " 0.0029164485,\n",
       " -0.058818743,\n",
       " 0.015010545,\n",
       " -0.00547767,\n",
       " 0.033678085,\n",
       " -0.044120926,\n",
       " 0.0053094313,\n",
       " -0.009705107,\n",
       " 0.018506415,\n",
       " -0.032899022,\n",
       " 0.008610945,\n",
       " 0.004711098,\n",
       " -0.02359606,\n",
       " 0.036915224,\n",
       " -0.024385016,\n",
       " 0.05358675,\n",
       " -0.035237525,\n",
       " -0.037300643,\n",
       " -0.023231318,\n",
       " 0.026352495,\n",
       " 0.06973572,\n",
       " -0.031704612,\n",
       " 0.0097267525,\n",
       " -0.056292042,\n",
       " 0.03712697,\n",
       " -0.0064819446,\n",
       " -0.046750147,\n",
       " -0.09289271,\n",
       " -0.03390805,\n",
       " 0.04556609,\n",
       " 0.0074357064,\n",
       " -0.015597343,\n",
       " 0.0040542185,\n",
       " -0.07472086,\n",
       " -0.005998594,\n",
       " -0.0393848,\n",
       " -0.011888741,\n",
       " 0.00928945,\n",
       " 0.037462957,\n",
       " 0.0020716474,\n",
       " 0.016934229,\n",
       " 0.05234935,\n",
       " 0.056728616,\n",
       " -0.01936841,\n",
       " 0.028804382,\n",
       " -0.111103185,\n",
       " -0.0044921623,\n",
       " 0.06677804,\n",
       " 0.013326151,\n",
       " -0.01708233,\n",
       " -0.0039696633,\n",
       " -0.035547797,\n",
       " -0.027487932,\n",
       " -0.04305848,\n",
       " -0.024637876,\n",
       " -0.0057464982,\n",
       " 0.04281373,\n",
       " 0.033118337,\n",
       " 0.0013633901,\n",
       " 0.032827925,\n",
       " -0.029723061,\n",
       " 0.027887613,\n",
       " -0.043198247,\n",
       " -0.022136463,\n",
       " -0.0034525336,\n",
       " 0.0086129615,\n",
       " 0.01905987,\n",
       " -0.024016295,\n",
       " 0.041305177,\n",
       " 0.108329155,\n",
       " 0.06734149,\n",
       " 0.028936112,\n",
       " 0.0096477,\n",
       " -0.03470397,\n",
       " 0.013826308,\n",
       " 0.0401158,\n",
       " -0.016229218,\n",
       " 0.02538722,\n",
       " -0.01935437,\n",
       " 0.034887962,\n",
       " 0.073989205,\n",
       " 0.040258817,\n",
       " -0.041560102,\n",
       " -0.06038568,\n",
       " 0.049743738,\n",
       " 0.02244838,\n",
       " 0.06871652,\n",
       " 0.035440695,\n",
       " 0.04750896,\n",
       " 0.048014704,\n",
       " 0.064166255,\n",
       " -0.025570847,\n",
       " -0.027907671,\n",
       " 0.01958712,\n",
       " 0.0064753573,\n",
       " 0.04868793,\n",
       " -0.009511809,\n",
       " -0.0028908032,\n",
       " -0.011687634,\n",
       " -0.03180688,\n",
       " 0.0639566,\n",
       " -0.027733449,\n",
       " 0.011007295,\n",
       " -0.066150196,\n",
       " -0.02735244,\n",
       " 0.035867028,\n",
       " 0.06280207,\n",
       " 0.019602591,\n",
       " -0.041468553,\n",
       " 0.012430453,\n",
       " 0.01810529,\n",
       " 0.05040266,\n",
       " 0.018354418,\n",
       " 0.041454513,\n",
       " -0.009909905,\n",
       " -0.0008147244,\n",
       " -0.040561114,\n",
       " -0.060472485,\n",
       " -0.014861396,\n",
       " -0.011399024,\n",
       " 0.020905972,\n",
       " 0.026155723,\n",
       " -0.003925259,\n",
       " 0.03583954,\n",
       " -0.01446684,\n",
       " -0.06633948,\n",
       " 0.0033607406,\n",
       " -0.052732095,\n",
       " -0.00014240322,\n",
       " -0.0038764623,\n",
       " -0.0615267,\n",
       " -0.012443867,\n",
       " -0.022158379,\n",
       " -0.04418049,\n",
       " 0.017846806,\n",
       " 0.02014427,\n",
       " 0.008702835,\n",
       " -0.044945728,\n",
       " 0.07126318,\n",
       " -0.0134299155,\n",
       " -0.013706234,\n",
       " -0.030122414,\n",
       " -0.015087667,\n",
       " -0.027198933,\n",
       " -0.011749509,\n",
       " -0.039526656,\n",
       " -0.01663261,\n",
       " 0.031778764,\n",
       " 0.018673394,\n",
       " 0.0030530891,\n",
       " 0.0025147707,\n",
       " -0.045832988,\n",
       " -0.025717363,\n",
       " 0.008489566,\n",
       " -0.017215742,\n",
       " -0.01712557,\n",
       " 0.0013872789,\n",
       " -0.0074855676,\n",
       " 0.026824784,\n",
       " -0.058755368,\n",
       " -0.02964301,\n",
       " 0.035982262,\n",
       " -0.027355596,\n",
       " 0.041900884,\n",
       " -0.039941017,\n",
       " 0.008208567,\n",
       " 0.00072801596,\n",
       " -0.026411913,\n",
       " 0.027470872,\n",
       " 0.038331848,\n",
       " -0.0034958576,\n",
       " -0.029965471,\n",
       " 0.007230371,\n",
       " -0.00095428067,\n",
       " -0.023924999,\n",
       " 0.03793381,\n",
       " -0.0036241296,\n",
       " 0.028229566,\n",
       " -0.0019915006,\n",
       " 0.055602998,\n",
       " 0.012693991,\n",
       " -0.022011567,\n",
       " 0.005437332,\n",
       " 0.03619445,\n",
       " 0.062837,\n",
       " -0.008943613,\n",
       " 0.008254157,\n",
       " -0.014834903,\n",
       " 0.048288506,\n",
       " 0.03225341,\n",
       " 0.03860849,\n",
       " -0.0051296754,\n",
       " -0.05434357,\n",
       " 0.037229944,\n",
       " 0.038676478,\n",
       " -0.018408645,\n",
       " -0.049270798,\n",
       " -0.012310484,\n",
       " 0.0127258105,\n",
       " 0.05320394,\n",
       " -0.026033383,\n",
       " 0.016251508,\n",
       " -0.019498369,\n",
       " -0.032719925,\n",
       " 0.038604222,\n",
       " 0.018875405,\n",
       " -0.05982896,\n",
       " 0.019321118,\n",
       " -0.048791002,\n",
       " 0.040527828,\n",
       " -0.0060996227,\n",
       " 0.04837171,\n",
       " 0.045780454,\n",
       " -0.0050942767,\n",
       " -0.009474927,\n",
       " -0.0126438765,\n",
       " -0.047415182,\n",
       " 0.0040736836,\n",
       " 0.03512219,\n",
       " -0.053599454,\n",
       " -0.015725708,\n",
       " -0.015918577,\n",
       " 0.018590096,\n",
       " -0.060008164,\n",
       " 0.009777594,\n",
       " 0.016664201,\n",
       " -0.021762926,\n",
       " 0.030429948,\n",
       " 0.020038541,\n",
       " 0.05516779,\n",
       " 0.016092826,\n",
       " -0.014300363,\n",
       " -0.009503281,\n",
       " -0.008627842,\n",
       " 0.01609288,\n",
       " -0.07334538,\n",
       " -0.012498555,\n",
       " -0.0020762256,\n",
       " -0.049901135,\n",
       " -0.0275057,\n",
       " 0.038069315,\n",
       " -0.0032574036,\n",
       " -0.039589327,\n",
       " -0.008738796,\n",
       " -0.012264821,\n",
       " 0.031807575,\n",
       " -0.050138995,\n",
       " 0.023247838,\n",
       " -0.03674072,\n",
       " 0.0403711,\n",
       " -0.03326908,\n",
       " -0.011649407,\n",
       " 0.040226366,\n",
       " -0.03675792,\n",
       " -0.024480622,\n",
       " -0.05824388,\n",
       " 0.02802075,\n",
       " 0.02483474,\n",
       " -0.031708166,\n",
       " -0.042278234,\n",
       " -0.018748146,\n",
       " 0.0021083523,\n",
       " -0.008041041,\n",
       " -0.02743517,\n",
       " -0.07056353,\n",
       " -0.025172926,\n",
       " 0.028103376,\n",
       " -0.018697789,\n",
       " -0.018101236,\n",
       " 0.049774256,\n",
       " -0.012424897,\n",
       " 0.041211206,\n",
       " 0.019704599,\n",
       " 0.04899325,\n",
       " 0.05093719,\n",
       " 0.017920334,\n",
       " 0.015921202,\n",
       " -0.0050943997,\n",
       " -0.03768877,\n",
       " 0.062194105,\n",
       " 0.021030584,\n",
       " -0.02254185,\n",
       " -0.07222084,\n",
       " 0.00029731676,\n",
       " -0.016347833,\n",
       " 0.029366182,\n",
       " 0.02529745,\n",
       " 0.028052228,\n",
       " -0.07911232,\n",
       " 0.0077353856,\n",
       " -0.021291938,\n",
       " 0.022128597,\n",
       " 0.006475075,\n",
       " -0.0028078756,\n",
       " -0.026898045,\n",
       " -0.03418993,\n",
       " -0.023054192,\n",
       " 0.0022493761,\n",
       " -0.03923166,\n",
       " 0.008252001,\n",
       " 0.040625755,\n",
       " 0.025935424,\n",
       " -0.013416763,\n",
       " 0.08128628,\n",
       " -0.053946987,\n",
       " -0.010945744,\n",
       " 0.010196616,\n",
       " -0.054451417,\n",
       " 0.05740274,\n",
       " -0.035342194,\n",
       " 0.0027831306,\n",
       " -0.01950415,\n",
       " -0.061551224,\n",
       " 0.06713983,\n",
       " -0.041256644,\n",
       " 0.025337506,\n",
       " 0.03727026,\n",
       " -0.006978335,\n",
       " 0.032713883,\n",
       " -0.0048742015,\n",
       " -0.041064337,\n",
       " 0.017653171,\n",
       " 0.029608015,\n",
       " -0.0351206,\n",
       " 0.012632532,\n",
       " 0.017508917,\n",
       " -0.007412464,\n",
       " -0.05902566,\n",
       " -0.041995037,\n",
       " -0.019574678,\n",
       " 0.025230013,\n",
       " -0.0011974798,\n",
       " -0.043264963,\n",
       " 0.020968124,\n",
       " 0.097715385,\n",
       " 0.013460854,\n",
       " -0.0004386104,\n",
       " 0.0070316773,\n",
       " 0.01801836,\n",
       " 0.07458026,\n",
       " 0.014873469,\n",
       " 0.03934818,\n",
       " 0.05876696,\n",
       " -0.010820406,\n",
       " 0.057144128,\n",
       " 0.041174415,\n",
       " -5.614727e-06,\n",
       " 0.012988716,\n",
       " -0.06023547,\n",
       " -0.034997687,\n",
       " 0.004914749,\n",
       " -0.0071611158,\n",
       " -0.024386294,\n",
       " -0.013776107,\n",
       " -0.073786646,\n",
       " -0.057799757,\n",
       " -0.040227998,\n",
       " -0.026728017,\n",
       " -0.031187164,\n",
       " -0.06813767,\n",
       " -0.008614718,\n",
       " -0.052472502,\n",
       " 0.013669863,\n",
       " 0.03136859,\n",
       " 0.00895871,\n",
       " -0.09724464,\n",
       " -0.07036025,\n",
       " -0.012833637,\n",
       " 0.025593396,\n",
       " -0.03351381,\n",
       " 0.034800764,\n",
       " 0.050468005,\n",
       " 0.0059871897,\n",
       " 0.017939568,\n",
       " -0.008072515,\n",
       " 0.005714174,\n",
       " -0.0050210417,\n",
       " -0.049213763,\n",
       " -0.017437791,\n",
       " -0.042688314,\n",
       " -0.013073437,\n",
       " 0.04072199,\n",
       " 0.004512855,\n",
       " -0.010328864,\n",
       " 0.0010824503,\n",
       " -0.053199865,\n",
       " 0.0047390065,\n",
       " -0.05277822,\n",
       " -0.022988614,\n",
       " 0.03812375,\n",
       " -0.03187885,\n",
       " 0.0274323,\n",
       " -0.0073503875,\n",
       " -0.00062709686,\n",
       " 0.0065004327,\n",
       " 0.026054038,\n",
       " -0.07452596,\n",
       " -0.0077091423,\n",
       " -0.003614513,\n",
       " -0.028333353,\n",
       " 0.025423184,\n",
       " -0.085276164,\n",
       " 0.027304046,\n",
       " -0.056819398,\n",
       " -0.0056164484,\n",
       " -0.02534934,\n",
       " -0.059827797,\n",
       " -0.028496874,\n",
       " 0.012353451,\n",
       " 0.0029291178,\n",
       " -0.058476858,\n",
       " -0.00577933,\n",
       " -0.064628266,\n",
       " -0.037222106,\n",
       " -0.04383538,\n",
       " -0.0807183,\n",
       " 0.063133605,\n",
       " -0.036544498,\n",
       " 0.03613718,\n",
       " -0.018216807,\n",
       " 0.0044921716,\n",
       " 0.07065448,\n",
       " 0.012319597,\n",
       " -0.01686765,\n",
       " -0.013246095,\n",
       " -0.07528062,\n",
       " -0.04388484,\n",
       " -0.0147007555,\n",
       " -0.06459963,\n",
       " 0.0031249186,\n",
       " 0.0030891113,\n",
       " -0.007820464,\n",
       " 0.00975866,\n",
       " -0.024452474,\n",
       " 0.018467195,\n",
       " 0.0021362395,\n",
       " -0.0106503265,\n",
       " -0.018340396,\n",
       " -0.040053863,\n",
       " 0.014091762,\n",
       " 0.0053143487,\n",
       " 0.060941212,\n",
       " -0.0055999085,\n",
       " -0.0022144169,\n",
       " -0.026828902,\n",
       " -0.059221033,\n",
       " -0.019295529,\n",
       " 0.012029709,\n",
       " -0.014316298,\n",
       " 0.0071216715,\n",
       " 0.041943256,\n",
       " 0.028590724,\n",
       " -0.01879845,\n",
       " 0.019048927,\n",
       " 0.0008425844,\n",
       " 0.014487807,\n",
       " 0.023856942,\n",
       " -0.14773203,\n",
       " 0.03438786,\n",
       " 0.03526517,\n",
       " -0.012380638,\n",
       " -0.0047208103,\n",
       " 0.008566032,\n",
       " -0.030049816,\n",
       " -0.0016053307,\n",
       " -0.004262701,\n",
       " 0.02332453,\n",
       " -0.020194052,\n",
       " -0.056156073,\n",
       " 0.010397034,\n",
       " 0.037239503,\n",
       " -0.020448182,\n",
       " 0.023099387,\n",
       " 0.010030295,\n",
       " -0.10026639,\n",
       " -0.043756027,\n",
       " -0.013170448,\n",
       " -0.08660198,\n",
       " 0.01328226,\n",
       " 0.0036437942,\n",
       " -0.0697274,\n",
       " -0.015171624,\n",
       " -0.028320305,\n",
       " 0.0954312,\n",
       " -0.06218155,\n",
       " -0.02801827,\n",
       " 0.010207587,\n",
       " 0.009326865,\n",
       " -0.009373653,\n",
       " 0.019834707,\n",
       " 0.01872402,\n",
       " 0.0125226,\n",
       " -0.0008095066,\n",
       " 0.0059696725,\n",
       " 0.016461048,\n",
       " -0.0011017488,\n",
       " -0.010809779,\n",
       " 0.0048057158,\n",
       " 0.021030119,\n",
       " -0.076933905,\n",
       " -0.0010300339,\n",
       " -0.0022651516,\n",
       " 0.0146102505,\n",
       " -0.015467062,\n",
       " 0.032426927,\n",
       " -0.04951603,\n",
       " 0.04839001,\n",
       " -0.019612702,\n",
       " 0.0023494812,\n",
       " -0.044119626,\n",
       " -0.0038815648,\n",
       " -0.0048788716,\n",
       " -0.020631725,\n",
       " -0.07080006,\n",
       " -0.0138387,\n",
       " -0.07585441,\n",
       " 0.112016216,\n",
       " 0.029148735,\n",
       " 0.0015084499,\n",
       " -0.037825786,\n",
       " 0.07467596,\n",
       " -0.020248627,\n",
       " 0.04064961,\n",
       " 0.0071538882,\n",
       " 0.016492287,\n",
       " -0.0028183705,\n",
       " 0.05037659,\n",
       " -0.0004902707,\n",
       " -0.014708449,\n",
       " 0.0062110717,\n",
       " 0.013448064,\n",
       " -0.009894746,\n",
       " 0.037842236,\n",
       " -0.032324642,\n",
       " 0.029238774,\n",
       " 0.009534211,\n",
       " -0.0023183546,\n",
       " -0.008357603,\n",
       " -0.00862601,\n",
       " -0.010616347,\n",
       " 0.04062255,\n",
       " 0.011934142,\n",
       " -0.06330767,\n",
       " 0.067283094,\n",
       " -0.022998845,\n",
       " 0.0075314175,\n",
       " 0.02309563,\n",
       " -0.0027532075,\n",
       " -0.015007144,\n",
       " 0.00996034,\n",
       " -0.011310604,\n",
       " -0.013035086,\n",
       " 0.02897127,\n",
       " -0.03804161,\n",
       " 0.07814838,\n",
       " -0.036366772,\n",
       " 0.055952806,\n",
       " 0.010155059,\n",
       " -0.017809305,\n",
       " -0.0002983406,\n",
       " 0.006254128,\n",
       " -0.017230751,\n",
       " 0.0060545825,\n",
       " -0.01676459,\n",
       " 0.01587055,\n",
       " 0.02182764,\n",
       " -0.0407388,\n",
       " -0.013183399,\n",
       " 0.053638674,\n",
       " 0.021247234,\n",
       " -0.038569067,\n",
       " -0.08257349,\n",
       " 0.015988842,\n",
       " -0.020657964,\n",
       " -0.0063912007,\n",
       " 0.00031771237,\n",
       " 0.0015731471,\n",
       " 0.0031316457,\n",
       " 0.04083921,\n",
       " -0.067720294,\n",
       " 0.046653725,\n",
       " 0.009121635,\n",
       " 0.011394796,\n",
       " 0.061881028,\n",
       " -0.0098185185,\n",
       " -0.000999809,\n",
       " -0.014653636,\n",
       " 0.0036619436,\n",
       " 0.0122311255,\n",
       " 0.01876932,\n",
       " 0.0032912132,\n",
       " 0.0015908165,\n",
       " -0.09495548,\n",
       " 0.02612664,\n",
       " 0.08732325,\n",
       " -0.033352423,\n",
       " -0.0318701,\n",
       " 0.08826379,\n",
       " 0.0488381,\n",
       " -0.064856015,\n",
       " -0.05385437,\n",
       " 0.025642961,\n",
       " -0.03286944,\n",
       " -0.0008289302,\n",
       " -0.013619189,\n",
       " -0.025139276,\n",
       " 0.025000367,\n",
       " 0.0041258745,\n",
       " -0.03665089,\n",
       " -0.013917268,\n",
       " 0.039829075,\n",
       " -0.012401263,\n",
       " -0.068842694,\n",
       " -0.015641667,\n",
       " -0.04501734,\n",
       " 0.011624829,\n",
       " 0.039560758,\n",
       " -0.034552973,\n",
       " -0.060517624,\n",
       " -0.018038735,\n",
       " -0.020248132,\n",
       " 0.0142803565,\n",
       " -0.063781336,\n",
       " 0.038486686,\n",
       " 0.03822097,\n",
       " 0.006952648,\n",
       " 0.004642177,\n",
       " 0.07043347,\n",
       " -0.021720733,\n",
       " 0.05204301,\n",
       " -0.0101216035,\n",
       " 0.040017214,\n",
       " 0.010548448,\n",
       " -0.03883784,\n",
       " -0.01373925,\n",
       " -0.01608768,\n",
       " 0.02169219,\n",
       " 0.008812028,\n",
       " 0.027786657,\n",
       " 0.014168503,\n",
       " -0.014115024,\n",
       " -0.031651914,\n",
       " 0.023075104,\n",
       " 0.007234328,\n",
       " -0.034412093,\n",
       " 0.018216131,\n",
       " 0.041799173,\n",
       " 0.013440881,\n",
       " -0.0006358503,\n",
       " 0.029478827,\n",
       " 0.005088581,\n",
       " 0.03787236,\n",
       " 0.008216172,\n",
       " -0.048466533,\n",
       " 0.0054278346,\n",
       " 0.014661404,\n",
       " -0.017638717,\n",
       " 0.032339524,\n",
       " 0.0130907,\n",
       " 0.045150973,\n",
       " -0.01352934,\n",
       " 0.0038604098,\n",
       " 0.029579034,\n",
       " -0.039316215,\n",
       " -0.037026383,\n",
       " 0.0051478823,\n",
       " 0.027194146,\n",
       " -0.08520211,\n",
       " 0.011815797,\n",
       " 0.022677029,\n",
       " -0.027454257,\n",
       " 0.071130015,\n",
       " -0.0011125033,\n",
       " 0.020692527,\n",
       " 0.032454737,\n",
       " -0.026999708,\n",
       " -0.054701928,\n",
       " 0.018761598,\n",
       " -0.038745083,\n",
       " 0.04997728,\n",
       " -0.0042743203,\n",
       " -0.0064638695,\n",
       " 0.07816588,\n",
       " -0.016364224,\n",
       " -0.043854073,\n",
       " 0.019416964,\n",
       " -0.03174321,\n",
       " 0.061369736,\n",
       " -0.008152962,\n",
       " 0.046147965,\n",
       " -0.040029213,\n",
       " -0.05472824,\n",
       " -0.027665414,\n",
       " -0.012780551,\n",
       " -0.024522172,\n",
       " 0.04749434,\n",
       " 0.013437903,\n",
       " -0.045792904,\n",
       " 0.014785363,\n",
       " -0.020525226,\n",
       " 0.029172104,\n",
       " -0.0041456665,\n",
       " -0.06490484,\n",
       " 0.05189873,\n",
       " -0.022138078,\n",
       " -0.0036276563,\n",
       " 0.052195795,\n",
       " -0.031138383,\n",
       " 0.0075283307,\n",
       " 0.024454355,\n",
       " -0.01259557,\n",
       " 0.010250895,\n",
       " -0.070984386,\n",
       " 0.036955617,\n",
       " 0.027977219,\n",
       " -0.013128852,\n",
       " -0.01818822,\n",
       " 0.011894322,\n",
       " -0.039779924,\n",
       " -0.010305635]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "result.embeddings[0].values"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a00edae7597f40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "lang"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7d4bea6d6d8d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added document 1\n",
      "Added document 2\n",
      "Added document 3\n",
      "Added document 4\n",
      "Added document 5\n",
      "Added document 6\n",
      "Added document 7\n",
      "Added document 8\n",
      "Added document 9\n",
      "Added document 10\n",
      "Added document 11\n",
      "Added document 12\n",
      "Added document 13\n",
      "Added document 14\n",
      "Added document 15\n",
      "Added document 16\n",
      "Added document 17\n",
      "Added document 18\n",
      "Added document 19\n",
      "Added document 20\n",
      "Added document 21\n",
      "Added document 22\n"
     ]
    }
   ],
   "source": [
    "#|export\n",
    "# db = create_chroma_db(documents, \"employee_manual\", language=lang)\n",
    "db = create_chroma_db(documents, \"deepseek_r1\")\n",
    "# chroma_client = chromadb.PersistentClient(path=\"../db\")\n",
    "# db = chroma_client.get_or_create_collection('deepseek_r1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db6f136a0ea2af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['siasun_qa_technology', 'employee_manual', 'deepseek_r1', 'siasun_qa_service']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chroma_client = chromadb.PersistentClient(path=\"../db\")\n",
    "# chroma_client.delete_collection(name='deepseek_r1')\n",
    "chroma_client.list_collections()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ab8a24de9976a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chroma_client = chromadb.Client()\n",
    "recs = db.peek(5)\n",
    "# df = pd.DataFrame(recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d647e4f8f58304f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_passage(query, db):\n",
    "    passage = db.query(query_texts=[query], n_results=1)['documents'][0][0]\n",
    "    return passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c2a68493cb7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "DeepSeek-R1 avoids introducing length bias during GPT-based evaluations, further solidifying\nits robustness across multiple tasks.\nOn math tasks, DeepSeek-R1 demonstrates performance on par with OpenAI-o1-1217,\nsurpassing other models by a large margin. A similar trend is observed on coding algorithm\ntasks, such as LiveCodeBench and Codeforces, where reasoning-focused models dominate these\nbenchmarks. On engineering-oriented coding tasks, OpenAI-o1-1217 outperforms DeepSeek-R1\non Aider but achieves comparable performance on SWE Verified. We believe the engineering\nperformance of DeepSeek-R1 will improve in the next version, as the amount of related RL\ntraining data currently remains very limited.\n3.2. Distilled Model Evaluation\nModel\nAIME 2024\nMATH-500\nGPQA\nLiveCode\nCodeForces\nDiamond\nBench\npass@1\ncons@64\npass@1\npass@1\npass@1\nrating\nGPT-4o-0513\n9.3\n13.4\n74.6\n49.9\n32.9\n759\nClaude-3.5-Sonnet-1022\n16.0\n26.7\n78.3\n65.0\n38.9\n717\nOpenAI-o1-mini\n63.6\n80.0\n90.0\n60.0\n53.8\n1820\nQwQ-32B-Preview\n50.0\n60.0\n90.6\n54.5\n41.9\n1316\nDeepSeek-R1-Distill-Qwen-1.5B\n28.9\n52.7\n83.9\n33.8\n16.9\n954\nDeepSeek-R1-Distill-Qwen-7B\n55.5\n83.3\n92.8\n49.1\n37.6\n1189\nDeepSeek-R1-Distill-Qwen-14B\n69.7\n80.0\n93.9\n59.1\n53.1\n1481\nDeepSeek-R1-Distill-Qwen-32B\n72.6\n83.3\n94.3\n62.1\n57.2\n1691\nDeepSeek-R1-Distill-Llama-8B\n50.4\n80.0\n89.1\n49.0\n39.6\n1205\nDeepSeek-R1-Distill-Llama-70B\n70.0\n86.7\n94.5\n65.2\n57.5\n1633\nTable 5 | Comparison of DeepSeek-R1 distilled models and other comparable models on\nreasoning-related benchmarks.\nAs shown in Table 5, simply distilling DeepSeek-R1’s outputs enables the efficient DeepSeek-\nR1-7B (i.e., DeepSeek-R1-Distill-Qwen-7B, abbreviated similarly below) to outperform non-\nreasoning models like GPT-4o-0513 across the board. DeepSeek-R1-14B surpasses QwQ-32B-\nPreview on all evaluation metrics, while DeepSeek-R1-32B and DeepSeek-R1-70B significantly\nexceed o1-mini on most benchmarks. These results demonstrate the strong potential of distilla-\ntion. Additionally, we found that applying RL to these distilled models yields significant further\ngains. We believe this warrants further exploration and therefore present only the results of the\nsimple SFT-distilled models here.\n4. Discussion\n4.1. Distillation v.s. Reinforcement Learning\nIn Section 3.2, we can see that by distilling DeepSeek-R1, the small model can achieve impressive\nresults. However, there is still one question left: can the model achieve comparable performance\nthrough the large-scale RL training discussed in the paper without distillation?\nTo answer this question, we conduct large-scale RL training on Qwen-32B-Base using math,\ncode, and STEM data, training for over 10K steps, resulting in DeepSeek-R1-Zero-Qwen-32B. The\nexperimental results, shown in Table 6, demonstrate that the 32B base model, after large-scale\n14",
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform embedding search\n",
    "passage = get_relevant_passage(\"How does the distilled models perform in evaluation comparing to other models?\", db)\n",
    "# passage = get_relevant_passage(\"休假规定\", db)\n",
    "Markdown(passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5246fdba83888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(query, relevant_passage):\n",
    "    escaped = relevant_passage.replace(\"'\", \"\").replace('\"', \"\").replace(\"\\n\", \" \")\n",
    "    prompt = (\"\"\"You are a helpful and informative bot that answers questions using text from the reference passage included below. \\\n",
    "    Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \\\n",
    "    However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \\\n",
    "    strike a friendly and converstional tone. \\\n",
    "    If the passage is irrelevant to the answer, you may ignore it. \\\n",
    "    Please answer in Chinese.\n",
    "    QUESTION: '{query}'\n",
    "    PASSAGE: '{relevant_passage}'\n",
    "\n",
    "        ANSWER:\n",
    "    \"\"\").format(query=query, relevant_passage=escaped)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b322ff6b274d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "You are a helpful and informative bot that answers questions using text from the reference passage included below.     Be sure to respond in a complete sentence, being comprehensive, including all relevant background information.     However, you are talking to a non-technical audience, so be sure to break down complicated concepts and     strike a friendly and converstional tone.     If the passage is irrelevant to the answer, you may ignore it.     Please answer in Chinese.\n    QUESTION: '这里的蒸馏模型在评估中的表现和其他模型比较的结果如何?'\n    PASSAGE: 'DeepSeek-R1 avoids introducing length bias during GPT-based evaluations, further solidifying its robustness across multiple tasks. On math tasks, DeepSeek-R1 demonstrates performance on par with OpenAI-o1-1217, surpassing other models by a large margin. A similar trend is observed on coding algorithm tasks, such as LiveCodeBench and Codeforces, where reasoning-focused models dominate these benchmarks. On engineering-oriented coding tasks, OpenAI-o1-1217 outperforms DeepSeek-R1 on Aider but achieves comparable performance on SWE Verified. We believe the engineering performance of DeepSeek-R1 will improve in the next version, as the amount of related RL training data currently remains very limited. 3.2. Distilled Model Evaluation Model AIME 2024 MATH-500 GPQA LiveCode CodeForces Diamond Bench pass@1 cons@64 pass@1 pass@1 pass@1 rating GPT-4o-0513 9.3 13.4 74.6 49.9 32.9 759 Claude-3.5-Sonnet-1022 16.0 26.7 78.3 65.0 38.9 717 OpenAI-o1-mini 63.6 80.0 90.0 60.0 53.8 1820 QwQ-32B-Preview 50.0 60.0 90.6 54.5 41.9 1316 DeepSeek-R1-Distill-Qwen-1.5B 28.9 52.7 83.9 33.8 16.9 954 DeepSeek-R1-Distill-Qwen-7B 55.5 83.3 92.8 49.1 37.6 1189 DeepSeek-R1-Distill-Qwen-14B 69.7 80.0 93.9 59.1 53.1 1481 DeepSeek-R1-Distill-Qwen-32B 72.6 83.3 94.3 62.1 57.2 1691 DeepSeek-R1-Distill-Llama-8B 50.4 80.0 89.1 49.0 39.6 1205 DeepSeek-R1-Distill-Llama-70B 70.0 86.7 94.5 65.2 57.5 1633 Table 5 | Comparison of DeepSeek-R1 distilled models and other comparable models on reasoning-related benchmarks. As shown in Table 5, simply distilling DeepSeek-R1’s outputs enables the efficient DeepSeek- R1-7B (i.e., DeepSeek-R1-Distill-Qwen-7B, abbreviated similarly below) to outperform non- reasoning models like GPT-4o-0513 across the board. DeepSeek-R1-14B surpasses QwQ-32B- Preview on all evaluation metrics, while DeepSeek-R1-32B and DeepSeek-R1-70B significantly exceed o1-mini on most benchmarks. These results demonstrate the strong potential of distilla- tion. Additionally, we found that applying RL to these distilled models yields significant further gains. We believe this warrants further exploration and therefore present only the results of the simple SFT-distilled models here. 4. Discussion 4.1. Distillation v.s. Reinforcement Learning In Section 3.2, we can see that by distilling DeepSeek-R1, the small model can achieve impressive results. However, there is still one question left: can the model achieve comparable performance through the large-scale RL training discussed in the paper without distillation? To answer this question, we conduct large-scale RL training on Qwen-32B-Base using math, code, and STEM data, training for over 10K steps, resulting in DeepSeek-R1-Zero-Qwen-32B. The experimental results, shown in Table 6, demonstrate that the 32B base model, after large-scale 14'\n\n        ANSWER:\n    ",
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query =\"How does the distilled models perform in evaluation comparing to other models?\"\n",
    "query =\"这里的蒸馏模型在评估中的表现和其他模型比较的结果如何?\"\n",
    "prompt = make_prompt(query, passage)\n",
    "Markdown(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae93ff6b9a61d7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "根据文章里的信息来看，这些通过“蒸馏”方法训练出来的 DeepSeek-R1 模型在评估中的表现相当不错呢！\n\n具体来说：\n\n1.  即使是相对较小的 **DeepSeek-R1-7B**（也就是 DeepSeek-R1-Distill-Qwen-7B 这个版本），在各项评估中都**全面超过了像 GPT-4o-0513 这样的模型**。\n2.  **DeepSeek-R1-14B** 这个版本，在所有的评估指标上都**超越了 QwQ-32B-Preview**。\n3.  而更大一些的 **DeepSeek-R1-32B** 和 **DeepSeek-R1-70B**，在**大部分的测试基准上都显著超过了 o1-mini**。\n\n总的来说，这些结果显示出，通过“蒸馏”这种技术，即使是相对小一些的模型也能达到非常好的性能，证明了这个方法的强大潜力。",
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# client = genai.Client(api_key=gemini_key)\n",
    "# response = client.models.generate_content(model=\"gemini-2.0-flash\", contents=prompt)\n",
    "response = client.models.generate_content(model=\"gemini-2.5-pro-exp-03-25\", contents=prompt)\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7b98c3785bb533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "Alright, let's break down how the distilled DeepSeek-R1 models perform compared to others! Basically, by using a technique called \"distillation\" on DeepSeek-R1, they've created smaller, more efficient versions. These smaller models, like the DeepSeek-R1-Distill-Qwen-7B, actually outperform other models that aren't focused on reasoning, such as GPT-4o-0513, across the board. Furthermore, the DeepSeek-R1-14B model does better than the QwQ-32B-Preview on all the tests, and the DeepSeek-R1-32B and DeepSeek-R1-70B models are much better than o1-mini on most of the benchmarks. So, distillation seems to be a pretty powerful tool!\n",
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "Markdown(response.text)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee657b91ee63efc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the document into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696557bdaac4d522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding = client.embeddings.create(\n",
    "#         model=\"deepseek/deepseek-r1:free\",\n",
    "#         input='Your text string goes here'\n",
    "#     )\n",
    "# embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e691b9105f92f799",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'OpenAIEmbeddingFunction' object has no attribute 'embed_query'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m deepseek_ef.embed_query(chunk.page_content)\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     embeddings = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerate_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/miniconda3-3.12-25.1.1-2/envs/cell/lib/python3.13/concurrent/futures/_base.py:619\u001b[39m, in \u001b[36mExecutor.map.<locals>.result_iterator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[32m    617\u001b[39m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[32m    618\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    621\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs.pop(), end_time - time.monotonic())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/miniconda3-3.12-25.1.1-2/envs/cell/lib/python3.13/concurrent/futures/_base.py:317\u001b[39m, in \u001b[36m_result_or_cancel\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    316\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    319\u001b[39m         fut.cancel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/miniconda3-3.12-25.1.1-2/envs/cell/lib/python3.13/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/miniconda3-3.12-25.1.1-2/envs/cell/lib/python3.13/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/miniconda3-3.12-25.1.1-2/envs/cell/lib/python3.13/concurrent/futures/thread.py:59\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mgenerate_embedding\u001b[39m\u001b[34m(chunk)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_embedding\u001b[39m(chunk):\n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m# return ollama_embedding_function.embed_query(chunk.page_content)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeepseek_ef\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_query\u001b[49m(chunk.page_content)\n",
      "\u001b[31mAttributeError\u001b[39m: 'OpenAIEmbeddingFunction' object has no attribute 'embed_query'"
     ]
    }
   ],
   "source": [
    "# Parallelize embedding generation\n",
    "def generate_embedding(chunk):\n",
    "    # return ollama_embedding_function.embed_query(chunk.page_content)\n",
    "    return google_ef.embed_query(chunk.page_content)\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    embeddings = list(executor.map(generate_embedding, chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aab85556fd1c15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anthropic's Model Context Protocol refers to the structured approach used in their AI models, particularly Claude, to manage conversational context effectively while prioritizing safety and coherence. Here's a breakdown of its key components:\n",
      "\n",
      "1. **Context Window Management**: \n",
      "   - Claude's large context window (up to 200k tokens) allows processing lengthy inputs, but the protocol ensures efficient retention of relevant information. Techniques like attention mechanisms prioritize recent or critical dialogue segments while avoiding overload.\n",
      "\n",
      "2. **Safety and Alignment**:\n",
      "   - Rooted in **Constitutional AI**, the protocol incorporates ethical guidelines to filter harmful requests, reduce biases, and ensure outputs align with human values. It may refuse unsafe tasks or seek clarification for ambiguous queries.\n",
      "\n",
      "3. **Multi-Turn Coherence**:\n",
      "   - Maintains consistency across long conversations by tracking dialogue history, user intent, and key entities. This avoids repetitive or contradictory responses common in less advanced models.\n",
      "\n",
      "4. **Structured Input/Output Handling**:\n",
      "   - Uses tokenization and context chunking to parse complex inputs (e.g., documents, code) and generate focused, context-aware replies. Tools like XML tagging might structure prompts for clarity.\n",
      "\n",
      "5. **Transparency and Control**:\n",
      "   - Features like system prompts allow users to set boundaries or guide model behavior explicitly (e.g., \"You are a helpful assistant focused on safety\"). This balances flexibility with constraint.\n",
      "\n",
      "While specifics are proprietary, Anthropic emphasizes these principles in publications like their **System Card** and **Constitutional AI framework**, highlighting their commitment to building reliable, ethical AI systems. The protocol aims to optimize both utility and safety in human-AI interactions.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "completion = client.chat.completions.create(\n",
    "  extra_headers={\n",
    "    \"HTTP-Referer\": \"binjian.github.io\", # Optional. Site URL for rankings on openrouter.ai.\n",
    "    \"X-Title\": \"binjian's digital garden\", # Optional. Site title for rankings on openrouter.ai.\n",
    "  },\n",
    "  extra_body={},\n",
    "  model=\"deepseek/deepseek-r1:free\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\", \"content\": \"You are a helpful assistant.\",\n",
    "      \"role\": \"user\", \"content\": \"What's Anthropic's Model context protocol?\"\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81899cd24437f8e",
   "metadata": {},
   "outputs": [],
   "source": "google_ef = embedding_functions.GoogleGenerativeAiEmbeddingFunction(api_key=gemini_key)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a4709412146528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_qa_to_csv(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Convert a text file with Q/A format to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        input_file: Path to the input text file\n",
    "        output_file: Path to the output CSV file\n",
    "    \"\"\"\n",
    "    # Read the content of the file\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # Split the content by 'Q' marker\n",
    "    qa_blocks = content.split('Q\\n')\n",
    "\n",
    "    qa_blks = [block.strip() for block in qa_blocks][1:]\n",
    "    # Remove empty blocks (like the first one if file starts with 'Q')\n",
    "    # qa_blocks = [[line for line in block.split('\\n') ] for block in qa_blks if block.strip()]\n",
    "    # Remove empty blocks (like the first one if file starts with 'Q')\n",
    "    # qa_blocks = [blk for block in qa_blocks if block.strip() for blk in block.strip()]\n",
    "\n",
    "    # Process each Q&A block\n",
    "    qa_pairs = []\n",
    "    for block in qa_blks:\n",
    "        # Split the block into lines\n",
    "        lines = block.strip().split('\\n')\n",
    "\n",
    "        if lines:\n",
    "            # First line is the question\n",
    "            question = lines[0]\n",
    "            # The rest are the answer\n",
    "            answer = '\\n'.join(lines[1:])\n",
    "\n",
    "            # Add the pair to our list\n",
    "            qa_pairs.append([question, answer])\n",
    "\n",
    "    # Write to CSV\n",
    "    with open(output_file, 'w', encoding='utf-8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        # Write header\n",
    "        writer.writerow(['Question', 'Answer'])\n",
    "        # Write Q&A pairs\n",
    "        for pair in qa_pairs:\n",
    "            writer.writerow(pair)\n",
    "    print(f\"Conversion complete. CSV file saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b867632cd7164a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete. CSV file saved to ../res/qa_service.csv\n",
      "Conversion complete. CSV file saved to ../res/qa_technology.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_files = [\"../res/qa_service.txt\", \"../res/qa_technology.txt\"]\n",
    "output_files = [\"../res/qa_service.csv\", \"../res/qa_technology.csv\"]\n",
    "for in_f, ot_f in zip(input_files, output_files):\n",
    "    convert_qa_to_csv(in_f, ot_f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87d7540e3a1b0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "client = chromadb.PersistentClient(path=\"../vdb\")\n",
    "# collections = [client.get_or_create_collection(name=\"siasun_qa_service\",embedding_function=deepseek_ef),\n",
    "#                 client.get_or_create_collection(name=\"siasun_qa_technology\",embedding_function=deepseek_ef)]\n",
    "collections = [client.get_or_create_collection(name=\"siasun_qa_service\", embedding_function=google_ef),\n",
    "                client.get_or_create_collection(name=\"siasun_qa_technology\", embedding_function=google_ef)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c4e9c21acabd5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'q2'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=2\n",
    "f'q{i}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8cffa926183329",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RetryError.__init__() missing 1 required positional argument: 'cause'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31m_InactiveRpcError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/miniconda3-3.12-25.1.1-2/envs/cell/lib/python3.13/site-packages/google/api_core/grpc_helpers.py:76\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/miniconda3-3.12-25.1.1-2/envs/cell/lib/python3.13/site-packages/grpc/_interceptor.py:277\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable.__call__\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m    269\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    270\u001b[39m     request: Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m    275\u001b[39m     compression: Optional[grpc.Compression] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    276\u001b[39m ) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     response, ignored_call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/miniconda3-3.12-25.1.1-2/envs/cell/lib/python3.13/site-packages/grpc/_interceptor.py:332\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._with_call\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m    329\u001b[39m call = \u001b[38;5;28mself\u001b[39m._interceptor.intercept_unary_unary(\n\u001b[32m    330\u001b[39m     continuation, client_call_details, request\n\u001b[32m    331\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, call\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/miniconda3-3.12-25.1.1-2/envs/cell/lib/python3.13/site-packages/grpc/_channel.py:440\u001b[39m, in \u001b[36m_InactiveRpcError.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    439\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"See grpc.Future.result.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/miniconda3-3.12-25.1.1-2/envs/cell/lib/python3.13/site-packages/grpc/_interceptor.py:315\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[39m\u001b[34m(new_details, request)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m     response, call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/miniconda3-3.12-25.1.1-2/envs/cell/lib/python3.13/site-packages/grpc/_channel.py:1198\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable.with_call\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m   1192\u001b[39m (\n\u001b[32m   1193\u001b[39m     state,\n\u001b[32m   1194\u001b[39m     call,\n\u001b[32m   1195\u001b[39m ) = \u001b[38;5;28mself\u001b[39m._blocking(\n\u001b[32m   1196\u001b[39m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[32m   1197\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1198\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/miniconda3-3.12-25.1.1-2/envs/cell/lib/python3.13/site-packages/grpc/_channel.py:1006\u001b[39m, in \u001b[36m_end_unary_response_blocking\u001b[39m\u001b[34m(state, call, with_call, deadline)\u001b[39m\n\u001b[32m   1005\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1006\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[31m_InactiveRpcError\u001b[39m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"failed to connect to all addresses; last error: UNKNOWN: ipv4:142.250.69.202:443: Failed to connect to remote host: Timeout occurred: FD Shutdown\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"failed to connect to all addresses; last error: UNKNOWN: ipv4:142.250.69.202:443: Failed to connect to remote host: Timeout occurred: FD Shutdown\", grpc_status:14, created_time:\"2025-03-24T17:41:29.255160718+08:00\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mServiceUnavailable\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/miniconda3-3.12-25.1.1-2/envs/cell/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:144\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m     result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/miniconda3-3.12-25.1.1-2/envs/cell/lib/python3.13/site-packages/google/api_core/timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/miniconda3-3.12-25.1.1-2/envs/cell/lib/python3.13/site-packages/google/api_core/grpc_helpers.py:78\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mServiceUnavailable\u001b[39m: 503 failed to connect to all addresses; last error: UNKNOWN: ipv4:142.250.69.202:443: Failed to connect to remote host: Timeout occurred: FD Shutdown",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRetryError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/miniconda3-3.12-25.1.1-2/envs/cell/lib/python3.13/site-packages/chromadb/api/models/CollectionCommon.py:90\u001b[39m, in \u001b[36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/miniconda3-3.12-25.1.1-2/envs/cell/lib/python3.13/site-packages/chromadb/api/models/CollectionCommon.py:213\u001b[39m, in \u001b[36mCollectionCommon._validate_and_prepare_add_request\u001b[39m\u001b[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[39m\n\u001b[32m    212\u001b[39m     validate_record_set_for_embedding(record_set=add_records)\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     add_embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embed_record_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_records\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/miniconda3-3.12-25.1.1-2/envs/cell/lib/python3.13/site-packages/chromadb/api/models/CollectionCommon.py:526\u001b[39m, in \u001b[36mCollectionCommon._embed_record_set\u001b[39m\u001b[34m(self, record_set, embeddable_fields)\u001b[39m\n\u001b[32m    525\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfield\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[literal-required]\u001b[39;00m\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    528\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mRecord does not contain any non-None fields that can be embedded.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    529\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEmbeddable Fields: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membeddable_fields\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    530\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRecord Fields: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecord_set\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    531\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/miniconda3-3.12-25.1.1-2/envs/cell/lib/python3.13/site-packages/chromadb/api/models/CollectionCommon.py:539\u001b[39m, in \u001b[36mCollectionCommon._embed\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    535\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    536\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou must provide an embedding function to compute embeddings.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    537\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://docs.trychroma.com/guides/embeddings\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    538\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embedding_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/miniconda3-3.12-25.1.1-2/envs/cell/lib/python3.13/site-packages/chromadb/api/types.py:466\u001b[39m, in \u001b[36mEmbeddingFunction.__init_subclass__.<locals>.__call__\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m: EmbeddingFunction[D], \u001b[38;5;28minput\u001b[39m: D) -> Embeddings:\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m     result = \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    467\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/miniconda3-3.12-25.1.1-2/envs/cell/lib/python3.13/site-packages/chromadb/utils/embedding_functions/google_embedding_function.py:74\u001b[39m, in \u001b[36mGoogleGenerativeAiEmbeddingFunction.__call__\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Documents) -> Embeddings:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_genai\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_task_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_task_title\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n\u001b[32m     81\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/miniconda3-3.12-25.1.1-2/envs/cell/lib/python3.13/site-packages/google/generativeai/embedding.py:213\u001b[39m, in \u001b[36membed_content\u001b[39m\u001b[34m(model, content, task_type, title, output_dimensionality, client, request_options)\u001b[39m\n\u001b[32m    206\u001b[39m embedding_request = protos.EmbedContentRequest(\n\u001b[32m    207\u001b[39m     model=model,\n\u001b[32m    208\u001b[39m     content=content_types.to_content(content),\n\u001b[32m   (...)\u001b[39m\u001b[32m    211\u001b[39m     output_dimensionality=output_dimensionality,\n\u001b[32m    212\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m embedding_response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_request\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m embedding_dict = \u001b[38;5;28mtype\u001b[39m(embedding_response).to_dict(embedding_response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/miniconda3-3.12-25.1.1-2/envs/cell/lib/python3.13/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:1263\u001b[39m, in \u001b[36mGenerativeServiceClient.embed_content\u001b[39m\u001b[34m(self, request, model, content, retry, timeout, metadata)\u001b[39m\n\u001b[32m   1262\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1263\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1264\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1265\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1266\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1267\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1268\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1270\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/miniconda3-3.12-25.1.1-2/envs/cell/lib/python3.13/site-packages/google/api_core/gapic_v1/method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/miniconda3-3.12-25.1.1-2/envs/cell/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:293\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    290\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    291\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    292\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/miniconda3-3.12-25.1.1-2/envs/cell/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:153\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    152\u001b[39m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/miniconda3-3.12-25.1.1-2/envs/cell/lib/python3.13/site-packages/google/api_core/retry/retry_base.py:221\u001b[39m, in \u001b[36m_retry_error_helper\u001b[39m\u001b[34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[39m\n\u001b[32m    216\u001b[39m     final_exc, source_exc = exc_factory_fn(\n\u001b[32m    217\u001b[39m         error_list,\n\u001b[32m    218\u001b[39m         RetryFailureReason.TIMEOUT,\n\u001b[32m    219\u001b[39m         original_timeout,\n\u001b[32m    220\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msource_exc\u001b[39;00m\n\u001b[32m    222\u001b[39m _LOGGER.debug(\n\u001b[32m    223\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mRetrying due to \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, sleeping \u001b[39m\u001b[38;5;132;01m{:.1f}\u001b[39;00m\u001b[33ms ...\u001b[39m\u001b[33m\"\u001b[39m.format(error_list[-\u001b[32m1\u001b[39m], next_sleep)\n\u001b[32m    224\u001b[39m )\n",
      "\u001b[31mRetryError\u001b[39m: Timeout of 60.0s exceeded, last exception: 503 failed to connect to all addresses; last error: UNKNOWN: ipv4:142.250.69.202:443: Failed to connect to remote host: Timeout occurred: FD Shutdown",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m reader = csv.reader(f)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(reader):\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[43mcollection\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msource\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msource\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43manswer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcollection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_q\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcollection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_a\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/miniconda3-3.12-25.1.1-2/envs/cell/lib/python3.13/site-packages/chromadb/api/models/Collection.py:82\u001b[39m, in \u001b[36mCollection.add\u001b[39m\u001b[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd\u001b[39m(\n\u001b[32m     48\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     49\u001b[39m     ids: OneOrMany[ID],\n\u001b[32m   (...)\u001b[39m\u001b[32m     59\u001b[39m     uris: Optional[OneOrMany[URI]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     60\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     61\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Add embeddings to the data store.\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[33;03m        ids: The ids of the embeddings you wish to add\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     79\u001b[39m \n\u001b[32m     80\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     add_request = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_and_prepare_add_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m        \u001b[49m\u001b[43muris\u001b[49m\u001b[43m=\u001b[49m\u001b[43muris\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28mself\u001b[39m._client._add(\n\u001b[32m     92\u001b[39m         collection_id=\u001b[38;5;28mself\u001b[39m.id,\n\u001b[32m     93\u001b[39m         ids=add_request[\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     99\u001b[39m         database=\u001b[38;5;28mself\u001b[39m.database,\n\u001b[32m    100\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/miniconda3-3.12-25.1.1-2/envs/cell/lib/python3.13/site-packages/chromadb/api/models/CollectionCommon.py:93\u001b[39m, in \u001b[36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     92\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m.with_traceback(e.__traceback__)\n",
      "\u001b[31mTypeError\u001b[39m: RetryError.__init__() missing 1 required positional argument: 'cause'"
     ]
    }
   ],
   "source": [
    "# |export\n",
    "for csv_file,collection in zip(output_files,collections):\n",
    "    with open(csv_file, newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for i, row in enumerate(reader):\n",
    "            collection.add(\n",
    "                documents = row,\n",
    "                metadatas = [{\"source\": \"question\"}, {\"source\": \"answer\"}],\n",
    "                ids = [f\"{collection.name}_q{i}\", f\"{collection.name}_a{i}\"]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f314ee21cd5cd18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你们的产品需要多久维护一次?'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|export\n",
    "queries=[\"你们的产品需要多久维护一次?\",\"我怎么设置机器人的安全工作区域?\"]\n",
    "queries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d885aba898533f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collections[0].query(\n",
    "    query_texts=queries,\n",
    "    n_results=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da70193ed6f00208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['siasun_qa_service_q2',\n",
       "   'siasun_qa_service_a9',\n",
       "   'siasun_qa_service_q21',\n",
       "   'siasun_qa_service_a10'],\n",
       "  ['siasun_qa_service_q1',\n",
       "   'siasun_qa_service_a19',\n",
       "   'siasun_qa_service_q22',\n",
       "   'siasun_qa_service_a18']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['你们的产品，多久需要维护一次？维护保养内容有哪些？',\n",
       "   '作业作为一个重要的单元，所以不能进行批量删除与添加，防止误操作造成损失。',\n",
       "   '宏作业是干什么用的？',\n",
       "   '新松有标准的视觉通讯协议，视觉厂家可以按照此协议进行开发适配。当前适配过的品牌有，沈阳自动化所，欧姆龙、海康、梅卡曼德、视比特、基恩士。'],\n",
       "  ['我们的人员调试不熟练，进度慢，你们厂家能负责调试吗？',\n",
       "   '机器人打精度用到的开关。',\n",
       "   '机器人可以存储多少个作业？',\n",
       "   '零位设定，是机器人在零位时的码盘值，码盘输入、码盘输出是以零位时为零开始计数的码盘值。']],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [[{'source': 'question'},\n",
       "   {'source': 'answer'},\n",
       "   {'source': 'question'},\n",
       "   {'source': 'answer'}],\n",
       "  [{'source': 'question'},\n",
       "   {'source': 'answer'},\n",
       "   {'source': 'question'},\n",
       "   {'source': 'answer'}]],\n",
       " 'distances': [[0.35835238473584624,\n",
       "   0.8026765812953612,\n",
       "   0.8398664268040978,\n",
       "   0.8905950951966901],\n",
       "  [0.5583867931983068,\n",
       "   0.5964258746641342,\n",
       "   0.6352793698255077,\n",
       "   0.7328770040724006]],\n",
       " 'included': [<IncludeEnum.distances: 'distances'>,\n",
       "  <IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "results"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a9c1661db02f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你们的产品，多久需要维护一次？维护保养内容有哪些？'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results['metadatas'][0] #[0]['source']\n",
    "results['documents'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d6a395a5b7a803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'siasun_qa_service'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colls = client.list_collections()\n",
    "colls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1332f82fbe473593",
   "metadata": {},
   "outputs": [],
   "source": "queries1 = ['你们的产品需要多久维护一次?','宏作业有什么用?']"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80b1495078948f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['siasun_qa_service_q2',\n",
       "   'siasun_qa_service_a9',\n",
       "   'siasun_qa_service_q21',\n",
       "   'siasun_qa_service_a10'],\n",
       "  ['siasun_qa_service_q16',\n",
       "   'siasun_qa_service_a20',\n",
       "   'siasun_qa_service_q13',\n",
       "   'siasun_qa_service_a7']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['你们的产品，多久需要维护一次？维护保养内容有哪些？',\n",
       "   '作业作为一个重要的单元，所以不能进行批量删除与添加，防止误操作造成损失。',\n",
       "   '宏作业是干什么用的？',\n",
       "   '新松有标准的视觉通讯协议，视觉厂家可以按照此协议进行开发适配。当前适配过的品牌有，沈阳自动化所，欧姆龙、海康、梅卡曼德、视比特、基恩士。'],\n",
       "  ['离线建模使用是样册的标准杆长，但实际机器人内有杆长补偿，这样建模对离线下发的点位准确性是否有影响？',\n",
       "   '有，离线接口库。',\n",
       "   '欧拉角是什么？有什么用处？新松机器人的欧拉角顺序是什么？',\n",
       "   '还有其它报警跟随，还需要查看其它报警来确认原因。弧焊与离线都会产生离线运动失败的报警。']],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [[{'source': 'question'},\n",
       "   {'source': 'answer'},\n",
       "   {'source': 'question'},\n",
       "   {'source': 'answer'}],\n",
       "  [{'source': 'question'},\n",
       "   {'source': 'answer'},\n",
       "   {'source': 'question'},\n",
       "   {'source': 'answer'}]],\n",
       " 'distances': [[0.35835238473584624,\n",
       "   0.8026765812953612,\n",
       "   0.8398664268040978,\n",
       "   0.8905950951966901],\n",
       "  [0.5112318120344393,\n",
       "   0.5778327751539375,\n",
       "   0.676073343384295,\n",
       "   0.7153126507950901]],\n",
       " 'included': [<IncludeEnum.distances: 'distances'>,\n",
       "  <IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results = collections[0].query(\n",
    "    query_texts=queries1,\n",
    "    n_results=4\n",
    ")\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b73eb7792be2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# question = \"你们的产品需要多久维护一次?\"\n",
    "# question = \"你们在售前评估上，如何帮助到我们?\"\n",
    "answers = []\n",
    "for collection in collections:\n",
    "    results = collection.query(\n",
    "        query_texts=queries,\n",
    "        n_results=4\n",
    "    )\n",
    "    docs = []\n",
    "    for i,metadata in enumerate(results['metadatas'][0]):\n",
    "        if metadata['source'] == 'question':\n",
    "            docs.append({'id': results['ids'][0][i],\n",
    "                         'document': results['documents'][0][i],\n",
    "                         'distance':results['distances'][0][i]})\n",
    "    df = pd.DataFrame(docs)\n",
    "    answers.append(df)\n",
    "df_answers = pd.concat(answers, axis=0,ignore_index=True)\n",
    "# df_answers = pd.stack(answers, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58ee1e3e4554ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          siasun_qa_technology_q10\n",
       "document         你们在售前评估上，能提供什么样的帮助？\n",
       "distance                    0.376322\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "df_answers.loc[df_answers['distance'].idxmin()]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622e9f7c853af379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'siasun_qa_technology_q10'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "id_q = df_answers.loc[df_answers['distance'].idxmin()]['id']\n",
    "id_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5929799653473da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['siasun', 'qa', 'technology', 'a10']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "id_a_list = id_q.split('_')\n",
    "id_a_list[-1] = id_a_list[-1].replace('q','a')\n",
    "id_a_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a65db8201c85e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'siasun_qa_technology_a10'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_a = '_'.join(id_a_list)\n",
    "id_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3b099a6b99bb79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll_idx = 0 if id_a_list[-2] == 'service' else 1\n",
    "coll_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a710916272b975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['部分情况可提供现场技术指导，提供成功应用案例经验支持，仿真模拟场景，评估负载等风险，提供机械、电气、软件接口对接。']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = collections[coll_idx].get(id_a)\n",
    "answer['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d82892da75b95cb",
   "metadata": {},
   "outputs": [],
   "source": "best_answer = df_answers.loc[df_answers['distance'].idxmin()]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea352cd4183e359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa(questions:list[str], collections:list[chromadb.Collection]=collections):\n",
    "    matched_questions = []\n",
    "    for collection in collections:\n",
    "        results = collection.query(\n",
    "            query_texts=questions,\n",
    "            n_results=4\n",
    "        )\n",
    "        docs = []\n",
    "        for i,metadata in enumerate(results['metadatas'][0]):\n",
    "            if metadata['source'] == 'question':\n",
    "                docs.append({'id': results['ids'][0][i],\n",
    "                                'document': results['documents'][0][i], \n",
    "                                'distance':results['distances'][0][i]})\n",
    "        df = pd.DataFrame(docs)\n",
    "        matched_questions.append(df)\n",
    "\n",
    "    df_matched_questions = pd.concat(matched_questions,axis=0,ignore_index=True)\n",
    "    best_match_q_id = df_matched_questions.loc[df_matched_questions['distance'].idxmin()]['id']\n",
    "    id_a_list = best_match_q_id.split('_')\n",
    "    id_a_list[-1] = id_a_list[-1].replace('q','a')\n",
    "    id_a = '_'.join(id_a_list)\n",
    "    coll_idx = 0 if id_a_list[-2] == 'service' else 1\n",
    "    best_answer = collections[coll_idx].get(id_a)['documents']\n",
    "    res_text = best_answer[0]\n",
    "    return res_text\n",
    "    # question =\n",
    "    # return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f749d9cc9a401a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['根据机器人的型号和实际使用情况，制定机器人的保养计划,一般分为日常、3 个月、6 个月、1 年期的维护保养。\\n需要对机器人进行日常点检和定期维护保养，点检工作主要检查设备是否存在漏油、异响、异常震动、异常报警；定期维护保养主要对油脂、线束护套、风扇、电机接头等易损位置进行检查，并定期更换润滑油。具体检验项目及维护周期详见安装维护手册。']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "question = \"你们的产品需要多久维护一次?\"\n",
    "res = qa(question)\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b2f84aa0784af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据机器人的型号和实际使用情况，制定机器人的保养计划,一般分为日常、3 个月、6 个月、1 年期的维护保养。\n",
      "需要对机器人进行日常点检和定期维护保养，点检工作主要检查设备是否存在漏油、异响、异常震动、异常报警；定期维护保养主要对油脂、线束护套、风扇、电机接头等易损位置进行检查，并定期更换润滑油。具体检验项目及维护周期详见安装维护手册。\n"
     ]
    }
   ],
   "source": "print(res[0])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2f204e6ab55bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"500\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# |export\n",
    "iface = gr.Interface(fn=qa, inputs=gr.Text(value=\"多久维护一次产品?\"), outputs=\"text\")\n",
    "iface.launch(width=500,share=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888b1b0530808ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "# this is only necessary in a notebook\n",
    "iface.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc11529d1b85a84",
   "metadata": {},
   "source": "## Create a `requirements.txt` file"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39a06f76c3da0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../requirements.txt\n",
    "fastcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df14eac7a58493f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648dc291964559de",
   "metadata": {},
   "outputs": [],
   "source": "# |default_exp data_preprocessing"
  },
  {
   "cell_type": "markdown",
   "id": "4755b2e93c82953c",
   "metadata": {},
   "source": "## Convert this notebook into a Gradio app"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9549f5fd490578dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nbdev.export import nb_export\n",
    "# nb_export('01_gradio.ipynb', lib_path='.', name='gradio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6118d49775df611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
